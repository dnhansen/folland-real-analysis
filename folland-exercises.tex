% Document setup
\documentclass[article, a4paper, 11pt, oneside]{memoir}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[UKenglish]{babel}

% Document info
\newcommand\doctitle{Folland: \emph{Real Analysis}}
\newcommand\docauthor{Danny NygÃ¥rd Hansen}

% Formatting and layout
\usepackage[autostyle]{csquotes}
\renewcommand{\mktextelp}{(\textellipsis\unkern)}
\usepackage[final]{microtype}
\usepackage{xcolor}
\frenchspacing
\usepackage{latex-sty/articlepagestyle}
\usepackage{latex-sty/articlesectionstyle}

% Fonts
\usepackage{amssymb}
\usepackage[largesmallcaps,partialup]{kpfonts}
\DeclareSymbolFontAlphabet{\mathrm}{operators} % https://tex.stackexchange.com/questions/40874/kpfonts-siunitx-and-math-alphabets
\linespread{1.06}
% \let\mathfrak\undefined
% \usepackage{eufrak}
\DeclareMathAlphabet\mathfrak{U}{euf}{m}{n}
\SetMathAlphabet\mathfrak{bold}{U}{euf}{b}{n}
% https://tex.stackexchange.com/questions/13815/kpfonts-with-eufrak
\usepackage{inconsolata}

% Hyperlinks
\usepackage{hyperref}
\definecolor{linkcolor}{HTML}{4f4fa3}
\hypersetup{%
	pdftitle=\doctitle,
	pdfauthor=\docauthor,
	colorlinks,
	linkcolor=linkcolor,
	citecolor=linkcolor,
	urlcolor=linkcolor,
	bookmarksnumbered=true
}

% Equation numbering
\numberwithin{equation}{chapter}

% Footnotes
\footmarkstyle{\textsuperscript{#1}\hspace{0.25em}}

% Mathematics
\usepackage{latex-sty/basicmathcommands}
\usepackage{latex-sty/framedtheorems}
\usepackage{latex-sty/topologycommands}
\usepackage{tikz-cd}
\tikzcdset{arrow style=math font} % https://tex.stackexchange.com/questions/300352/equalities-look-broken-with-tikz-cd-and-math-font
\usetikzlibrary{babel}

% Lists
\usepackage{enumitem}
\setenumerate[0]{label=\normalfont(\alph*)}
\setlist{
    listparindent=\parindent,
    parsep=0pt,
}

% Bibliography
\usepackage[backend=biber, style=authoryear, maxcitenames=2, useprefix]{biblatex}
\addbibresource{references.bib}

% Title
\title{\doctitle}
\author{\docauthor}

\newcommand{\setF}{\mathbb{F}}
\newcommand{\ev}{\mathrm{ev}}
\newcommand{\calT}{\mathcal{T}}
\newcommand{\calU}{\mathcal{U}}
\newcommand{\calB}{\mathcal{B}}
\newcommand{\calE}{\mathcal{E}}
\newcommand{\calC}{\mathcal{C}}
\newcommand{\calD}{\mathcal{D}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calG}{\mathcal{G}}
\newcommand{\calM}{\mathcal{M}}
\newcommand{\calN}{\mathcal{N}}
\newcommand{\calA}{\mathcal{A}}
\newcommand{\calP}{\mathcal{P}}
\newcommand{\calR}{\mathcal{R}}
\newcommand{\calH}{\mathcal{H}}
\newcommand{\calK}{\mathcal{K}}
\newcommand{\calL}{\mathcal{L}}
\newcommand{\borel}{\mathcal{B}}
\newcommand{\measurable}{\mathcal{M}}
\newcommand{\wto}{\Rightarrow}
\DeclarePairedDelimiter{\net}{\langle}{\rangle}
\newcommand{\strucS}{\mathfrak{S}}
\DeclarePairedDelimiter{\gen}{\langle}{\rangle} % Generating set
\newcommand{\frakL}{\mathfrak{L}}

\newcommand{\bbK}{\mathbb{K}}

\DeclareMathOperator{\Span}{span}
\DeclareMathOperator*{\slim}{s-lim}

\newenvironment{displaytheorem}{%
	\begin{displayquote}\itshape%
}{%
	\end{displayquote}%
}


%% Framed exercise environment

\mdfdefinestyle{swannexercise}{%
    skipabove=0.5em plus 0.4em minus 0.2em,
	skipbelow=0.5em plus 0.4em minus 0.2em,
	leftmargin=-5pt,
	rightmargin=-5pt,
	innerleftmargin=5pt,
	innerrightmargin=5pt,
	innertopmargin=5pt,
	innerbottommargin=4pt,
	linewidth=0pt,
	splittopskip=1.2em minus 0.2em,
	splitbottomskip=0.5em plus 0.2em minus 0.1em,
	backgroundcolor=backgroundcolor,
	frametitlebackgroundcolor=titlecolor,
	frametitlefont={\scshape},
    theoremseparator={\space\thechapter},
    theoremspace={.},
	frametitleaboveskip=3pt,
	frametitlebelowskip=2pt
}

\mdtheorem[style=swannexercise]{exerciseframed}{Exercise}

\let\oldexerciseframed\exerciseframed
\renewcommand{\exerciseframed}{%
  \crefalias{theorem}{exerciseframed}%
  \oldexerciseframed}

\makeatother



\theoremstyle{nonumberplain}
\theoremsymbol{\ensuremath{\square}}
\newtheorem{solution}{Solution}

\let\oldsolution\solution
\renewcommand{\solution}{%
  \crefalias{theorem}{solution}%
  \oldsolution}

\newcommand{\solutionlabelfont}[1]{{\normalfont\color{linkcolor}#1}}
\newlist{solutionsec}{enumerate}{1}
\setlist[solutionsec]{leftmargin=0pt, parsep=0pt, listparindent=\parindent, font=\solutionlabelfont, label=(\alph*), labelsep=0pt, labelwidth=20pt, itemindent=20pt, align=left, itemsep=10pt}


\begin{document}

\maketitle

\setcounter{chapter}{-1}
\chapter{Introduction}

\begin{itemize}
	\item We use the letter $d$ to denote vector spaces dimensions, freeing up $n$ to be used as an index, e.g. in sequences. In particular we write $\reals^d$ and $\complex^d$.
	\item The Lebesgue measure on $\reals^d$ is denoted $\lambda_d$, and $\lambda = \lambda_1$.
	\item The symbol $\bbK$ denotes either the real or complex numbers.
	\item The unit sphere in $\reals^{n+1}$ is denoted $\sphere^n$.
	\item We denote the power set of a set $X$ by $\powerset{X}$.
	\item The restriction of a function $f \colon X \to Y$ to a subset $A \subseteq X$ is denoted $f|_A$.
	\item Whenever we need to make the distinction, $\calL^p(\mu)$ refers to the space of $\mu$-$p$-integrable functions, while $L^p(\mu)$ denotes the quotient of $\calL^p(\mu)$ with the subspace of functions that are zero $\mu$-a.e.
	\item The space of bounded operators between normed spaces $X$ and $Y$ is denoted $\calB(X,Y)$.
	\item The bounded and continuous complex-valued functions on a topological space $X$ is denoted $C_b(X)$.
	\item A vector space equipped with an inner product is called an \emph{inner product space}.
\end{itemize}




\chapter{Measures}

\addtocounter{section}{1}
\section[Sigma-algebras][$\sigma$-algebras]{$\sigma$-algebras}

\begin{exerciseframed*}[1]
    Let $\calM$ be an infinite $\sigma$-algebra.
    %
    \begin{enumerate}
        \item $\calM$ contains an infinite sequence of disjoint sets.
        \item $\card{\calM} \geq \mathfrak{c}$.
    \end{enumerate}
\end{exerciseframed*}
%
Of course part (a) is trivial unless we require the sets to be nonempty.

\begin{solution}
\begin{solutionsec}
	\item We show by contraposition that there exists a nonempty set $A \in \calM$ such that the restriction of $\calM$ to $A^c$ is infinite. That is, assuming that no such set exists, we show that $\calM$ is finite. Pick any nonempty $A \in \calM$. Then the restriction of $\calM$ to $A$ and $A^c$ respectively are both finite. For any $B \in \calM$ we can write
	%
	\begin{equation*}
		B = (B \intersect A) \union (B \intersect A^c).
	\end{equation*}
	%
	But each set in the union lies in one of the restrictions, so there are finitely many decompositions like the one above, so there are finitely many sets $B \in \calM$.
	
	Now construct the sequence: Pick $A \in \calM$ as above, restrict $\calM$ to $A^c$, and continue recursively.
	
	\item Let $(A_n)$ be the sequence constructed above. There is an injection $\phi\colon 2^\naturals \to \calM$ given by $\phi(I) = \bigunion_{i \in I} A_i$ (injectivity follows since the sets in the sequence are disjoint). Hence $\card{\calM} \geq \card{\powerset\naturals} = \mathfrak{c}$.
\end{solutionsec}
\end{solution}


% \subsection{Exercise 5}



\section{Measures}

\begin{exerciseframed*}[14]
    If $\mu$ is a semifinite measure and $\mu(E) = \infty$, for any $C > 0$ there exists $F \subseteq E$ with $C < \mu(F) < \infty$.
\end{exerciseframed*}

\begin{solution}
	Consider
	%
	\begin{equation*}
		S = \sup \set{ \mu(F) }{ F \subseteq E, \mu(F) < \infty }.
	\end{equation*}
	%
	If $S = \infty$, then the result is obvious. So assume towards a contradiction that $S < \infty$. For $n \in \naturals$ choose $F_n \subseteq E$ with $\mu(F_n) < \infty$ such that
	%
	\begin{equation*}
		S - \frac{1}{n} \leq \mu(F_n) \leq S.
	\end{equation*}
	%
	Put $G_k = \bigunion_{n=1}^k F_n$. Then $G_k \subseteq E$ and $\mu(G_k) < \infty$, so the same inequality holds with $F_n$ replaced by $G_k$. Now putting $G = \bigunion_{k \in \naturals} G_k$, continuity of $\mu$ gives
	%
	\begin{equation*}
		S - \frac{1}{n} \leq \mu(G) \leq S
	\end{equation*}
	%
	for all $n \in \naturals$, so $\mu(G) = S$.
	
	By assumption $\mu(E \setminus G) = \infty$, so $E \setminus G$ contains a set $G' \in \calM$ such that $0 < \mu(G') < \infty$. But then
	%
	\begin{equation*}
		\mu(G \union G') = \mu(G) + \mu(G') > S,
	\end{equation*}
	%
	a contradiction.
\end{solution}


\begin{exerciseframed*}[16]
    Let $(X,\calM,\mu)$ be a measure space. A set $E \subseteq X$ is called \emph{locally measurable} if $E \intersect A \in \calM$ for all $A \in \calM$ such that $\mu(A) < \infty$. Let $\widetilde{\calM}$ be the collection of all locally measurable sets. Clearly $\calM \subseteq \widetilde{\calM}$; if $\calM = \widetilde{\calM}$, then $\mu$ is called \emph{saturated}.
    %
    \begin{enumerate}[label=(\alph*)]
        \item If $\mu$ is $\sigma$-finite, then $\mu$ is saturated.
        \item $\widetilde{\calM}$ is a $\sigma$-algebra.
        \item Define $\tilde\mu$ on $\widetilde{\calM}$ by $\tilde\mu(E) = \mu(E)$ if $E \in \calM$ and $\tilde\mu(E) = \infty$ otherwise. Then $\tilde\mu$ is a saturated measure on $\widetilde{\calM}$, called the \emph{saturation} of $\mu$.
        \item If $\mu$ is complete, so is $\tilde\mu$.
        \item Suppose that $\mu$ is semifinite. For $E \in \widetilde{\calM}$ define
        %
        \begin{equation*}
            \underline\mu(E)
                = \sup\set{\mu(A)}{\text{$A \in \calM$ and $A \subseteq E$}}.
        \end{equation*}
        %
        Then $\underline\mu$ is a saturated measure on $\widetilde{\calM}$ that extends $\mu$.

        \item Let $X_1,X_2$ be disjoint uncountable sets, $X = X_1 \union X_2$, and $\calM$ the $\sigma$-algebra of countable or co-countable sets in $X$. Let $\mu_0$ be counting measure on $\powerset{X_1}$, and define $\mu$ on $\calM$ by $\mu(E) = \mu_0(E \intersect X_1)$. Then $\mu$ is a measure on $\calM$, $\widetilde\calM = \powerset{X}$, and in the notation of parts (c) and (e), $\tilde\mu \neq \underline\mu$.
    \end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item Assume that $\mu$ is $\sigma$-finite, and let $E \subseteq X$ be locally measurable. Let $(A_n) \subseteq \calM$ be such that $X = \bigunion_{n \in \setN} A_n$ and $\mu(A_n) < \infty$. Then $E \intersect A_n \in \calM$, and so $E = \bigunion_{n \in \setN} (E \intersect A_n) \in \calM$.
	
	\item Clearly we have $X \in \widetilde\calM$. Then let $(E_n) \subseteq \widetilde\calM$, and let $A \in \calM$ with $\mu(A) < \infty$. Then
	%
	\begin{equation*}
		A \intersect \bigunion_{n \in \setN} E_n
			= \bigunion_{n \in \setN} (A \intersect E_n)
			\in \calM,
	\end{equation*}
	%
	so $\bigunion_{n \in \setN} E_n \in \widetilde\calM$. Finally let $E \in \widetilde\calM$ and $A \in \calM$ with $\mu(A) < \infty$. Then
	%
	\begin{equation*}
		E^c \intersect A
			= A \setminus E
			= A \setminus (E \intersect A)
			= (E \intersect A)^c \intersect A
			\in \calM
	\end{equation*}
	%
	since $E \intersect A \in \calM$, so $E^c \in \widetilde\calM$.

	\item We first show that $\tilde\mu$ is a measure. Clearly $\tilde\mu(\emptyset) = 0$, so let $(E_n)$ be a sequence of disjoint sets in $\widetilde\calM$, and let $E = \bigunion_{n\in\naturals} E_n$. Say that $E_m$ does not lie in $\calM$ for some $m \in \naturals$. Then we must have $\tilde\mu(E) = \infty$, since otherwise $E \in \calM$ with $\mu(E) < \infty$, and hence $E_m = E_m \intersect E \in \calM$. Thus we have
    %
    \begin{equation*}
        \sum_{n=1}^\infty \tilde\mu(E_n)
            \geq \tilde\mu(E_m)
            = \infty
            = \tilde\mu(E),
    \end{equation*}
    %
    so $\sum_{n=1}^\infty \tilde\mu(E_n) = \tilde\mu(E)$. The same is obviously true if all $E_n$ lie in $\calM$.
    
    Next we show that $\tilde\mu$ is saturated, i.e. that $\widetilde{\widetilde\calM} \subseteq \widetilde\calM$, so let $E \in \widetilde{\widetilde\calM}$. For all $A \in \widetilde{\calM}$ with $\tilde\mu(A) < \infty$ we then have $E \intersect A \in \widetilde{\calM}$. By definition of $\tilde\mu$ we must have $A \in \calM$, so we also have
	%
	\begin{equation*}
		E \intersect A
			= (E \intersect A) \intersect A
			\in \calM.
	\end{equation*}
	%
	And since this is true for all $A \in \calM$ with $\mu(A) < \infty$, it follows that $E \in \widetilde{\calM}$.

	In some sense, the fact that $\tilde{\mu}$ is saturated is obvious: The more sets of finite measure, the harder it is to be saturated, and vice-versa. On the other hand, the sets of infinite measure are irrelevant, so since the only new sets in $\widetilde\calM$ have infinite measure, they cannot affect whether the measure is saturated or not.

	\item Assume that $\mu$ is complete. Let $F \subseteq X$ be such that there is a set $E \in \widetilde{\calM}$ with $F \subseteq E$ and $\tilde\mu(E) = 0$. Then also $E \in \calM$, and since $\mu$ is complete we have $F \in \calM \subseteq \widetilde{\calM}$ as desired. Or more succinctly: Saturating a measure only introduces sets of infinite measure, so it does not introduce any null-sets.

	\item Assume that $\mu$ is semifinite. We first show that $\underline\mu$ is a measure. Clearly $\underline\mu(\emptyset) = 0$, so let $(E_n) \subseteq \widetilde{\calM}$ be a sequence of disjoint sets. Clearly $\underline\mu$ is increasing, so sigma-additivity is obvious if any of the sets $E_n$ have infinite measure. Assume then that $\underline\mu(E_n) < \infty$ for all $n \in \setN$. Let $\epsilon > 0$, and choose $A_n \in \calM$ such that $A_n \subseteq E_n$ and $\underline\mu(E_n) \leq \mu(A_n) + \epsilon/2^n$. Then
	%
	\begin{equation*}
		\underline\mu \bigl( \bigunion_{n \in \setN} E_n \bigr)
			\geq \mu \bigl( \bigunion_{n \in \setN} A_n \bigr)
			= \sum_{n=1}^\infty \mu(A_n)
			\geq \sum_{n=1}^\infty \mu(E_n) - \epsilon.
	\end{equation*}
	%
	Since this holds for all $\epsilon > 0$, we obtain the first inequality. For the other inequality, let $E = \bigunion_{n \in \setN} E_n$, and first assume that $\underline\mu(E) = \infty$. Pick $A \in \calM$ with $A \subseteq E$. Since $\mu$ is semifinite, we can choose $A$ such that $C < \mu(A) < \infty$ for any given $C > 0$. Letting $A_n = A \intersect E_n \in \calM$ we get
	%
	\begin{equation*}
		C
			< \mu(A)
			= \sum_{n=1}^\infty \mu(A_n)
			\leq \sum_{n=1}^\infty \underline\mu(E_n),
	\end{equation*}
	%
	and since $C$ is arbitrary, we get $\sum_{n=1}^\infty \underline\mu(E_n) = \infty$. If instead $\underline\mu(E) < \infty$, pick $A \subseteq E$ with $A \in \calM$ and $\underline\mu(E) \leq \mu(A) + \epsilon$. Again letting $A_n = A \intersect E_n$ we get
	%
	\begin{equation*}
		\underline\mu(E) - \epsilon
			\leq \mu(A)
			= \sum_{n=1}^\infty \mu(A_n)
			\leq \sum_{n=1}^\infty \underline\mu(E_n).
	\end{equation*}
	%
	And since $\epsilon$ is arbitrary, we obtain the other inequality.

	Next we show that $\underline\mu$ is saturated. Letting $E$ be locally $\underline\mu$-measurable, we must show that $E$ is also locally $\mu$-measurable. So let $A \in \calM$ with $\mu(A) < \infty$. Then $\underline\mu(A) < \infty$, and so $E \intersect A \in \widetilde{\calM}$. But then
	%
	\begin{equation*}
		E \intersect A
			= (E \intersect A) \intersect A
			\in \calM,
	\end{equation*}
	%
	as desired.

	\item It is pretty obvious that $\mu$ is a measure on $\calM$. Then let $E \subseteq X$ and $A \in \calM$ with $\mu(A) < \infty$. Then $A \intersect X_1$ must be finite, and so $A$ is not co-countable. But then it is countable, and so is $E \intersect A$, hence $E \intersect A \in \calM$. Thus every subset of $X$ is locally measurable.
	
	Notice that $\mu$ is semifinite. We have $\tilde\mu(X_2) = \infty$ since $X_2 \not\in \calM$, but $\underline\mu(X_2) = 0$ since every subset of $X_2$ is disjoint from $X_1$, and so is has measure zero.
\end{solutionsec}
\end{solution}


\section{Outer Measures}

% \subsection{Exercise 17}

% The inequality $\leq$ holds by definition. For the other inequality, notice that
% %
% \begin{align*}
% 	\mu^* \bigl( E \intersect \bigunion_{j \in \setN} A_j \bigr)
% 		&= \mu^*(E \intersect A_1) + \mu^* \bigl( E \intersect \bigunion_{j=2}^\infty A_j \bigr) \\
% 		&= \sum_{j=1}^n \mu^*(E \intersect A_j) + \mu^* \bigl( E \intersect \bigunion_{j=n+1}^\infty A_j \bigr) \\
% 		&\geq \sum_{j=1}^n \mu^*(E \intersect A_j)
% \end{align*}
% %
% for all $n \in \setN$. Letting $n \to \infty$ proves the inequality.


\begin{exerciseframed*}[18]
    Let $\calA \subseteq \powerset{X}$ be an algebra, $\calA_\sigma$ the collection of countable unions of sets in $\calA$, and $\calA_{\sigma\delta}$ the collection of countable intersections of sets in $\calA_\sigma$. Let $\mu_0$ be a premeasure on $\calA$ and $\mu^*$ the induced outer measure.
    %
    \begin{enumerate}
        \item For any $E \subseteq X$ and $\epsilon > 0$ there exists $A \in \calA_\sigma$ with $E \subseteq A$ with $\mu^*(A) \leq \mu^*(E) + \epsilon$.

        \item If $\mu^*(E) < \infty$, then $E$ is $\mu^*$-measurable iff there exists $B \in \calA_{\sigma\delta}$ with $E \subseteq B$ and $\mu^*(B \setminus E) = 0$.

        \item If $\mu_0$ is $\sigma$-finite, the restriction $\mu^*(E) < \infty$ in (b) is superfluous.
    \end{enumerate}
\end{exerciseframed*}


\begin{solution}
\begin{solutionsec}
	\item Let $E \subseteq X$ and $\epsilon > 0$. The definition of $\mu^*$ yields a sequence $(A_n) \subseteq \calA$ such that $E \subseteq \bigunion_{n\in\naturals} A_n$ and $\sum_{n=1}^\infty \mu_0(A_n) \leq \mu^*(E) + \epsilon$. It follows that
	%
	\begin{equation*}
		\mu^*(E) + \epsilon
			\geq \sum_{n=1}^\infty \mu_0(A_n)
			= \sum_{n=1}^\infty \mu^*(A_n)
			\geq \mu^* \Bigl( \bigunion_{n \in \setN} A_n \Bigr).
	\end{equation*}

	\item Let $E \subseteq X$. For $n \in \setN$ there is a set $B_n \in \calA_\sigma$ such that $E \subseteq B_n$ and $\mu^*(B_n) \leq \mu^*(E) + 1/n$. Letting $B = \bigintersect_{n \in \setN} B_n \in \calA_{\sigma\delta}$ we get $\mu^*(B) \leq \mu^*(E)$, and since $E \subseteq B$ we also have the opposite inequality, so $\mu^*(B) = \mu^*(E)$.
	
	Now assume that $\mu^*(E) < \infty$ and that $E$ is $\mu^*$-measurable. Then
	%
	\begin{equation*}
		\mu^*(B)
			= \mu^*(B \intersect E) + \mu^*(B \intersect E^c)
			= \mu^*(E) + \mu^*(B \setminus E),
	\end{equation*}
	%
	from which it follows that $\mu^*(B \setminus E) = 0$.

	Conversely, assume that there is a $B \in \calA_{\sigma\delta}$ with $E \subseteq B$ and $\mu^*(B \setminus E) = 0$. Then $B$ lies in the $\sigma$-algebra generated by $\calA$, so it is $\mu^*$-measurable. Let $A \subseteq X$. Then
	%
	\begin{align*}
		\mu^*(A \intersect E^c)
			&\leq \mu^*(A \intersect E^c \intersect B) + \mu^*(A \intersect E^c \intersect B^c) \\
			&= \mu^*(A \intersect (B \union E)^c) \\
			&= \mu^*(A \intersect B^c),
	\end{align*}
	%
	and so
	%
	\begin{equation*}
		\mu^*(A \intersect E) + \mu^*(A \intersect E^c)
			\leq \mu^*(A \intersect B) + \mu^*(A \intersect B^c)
			= \mu^*(A),
	\end{equation*}
	%
	showing that $E$ is $\mu^*$-measurable. (Notice that we haven't used that $\mu^*(E) < \infty$ for the second implication.)

	\item We only need to prove the first implication above. By $\sigma$-finiteness of $\mu_0$, let $(E_n)$ be a sequence of subsets of $X$ such that $\mu^*(E_n) < \infty$ and $E = \bigunion_{n \in \setN} E_n$. Let $\epsilon > 0$. Then there are sets $A_n \in \calA_\sigma$ such that $\mu^*(A_n) \leq \mu^*(E_n) + \epsilon/2^n$. Letting $B_\epsilon = \bigunion_{n \in \setN} A_n \in \calA_\sigma$ we get
	%
	\begin{equation*}
		\mu^*(B_\epsilon \setminus E)
			= \mu^* \Bigl( \bigunion_{n \in \setN} (A_n \intersect E^c) \Bigr)
			\leq \mu^* \Bigl( \bigunion_{n \in \setN} (A_n \intersect E_n^c) \Bigr)
			\leq \sum_{n=1}^\infty \mu^*(A_n \setminus E_n)
			\leq \epsilon.
	\end{equation*}
	%
	Finally we let $B = \bigintersect_{k \in \setN} B_{1/k} \in \calA_{\sigma\delta}$, and we get $\mu^*(B \setminus E) = 0$ as desired.
\end{solutionsec}
\end{solution}

\begin{remark*}
    Notice that (b) and (c) in particular show that any Lebesgue measurable set $E$, and therefore any Borel set, is the intersection of a $G_\delta$ set $B$ and a Lebesgue null set $B \setminus E$.
\end{remark*}


\begin{exerciseframed*}[20]
    Let $\mu^*$ be an outer measure on $X$, $\calM^*$ the $\sigma$-algebra of $\mu^*$-measurable sets, $\overline\mu = \mu^*|_{\calM^*}$, and $\mu^+$ the outer measure induced by $\overline\mu$ as in (1.12) (with $\overline\mu$ and $\calM^*$ replacing $\mu_0$ and $\calA$).
    %
    \begin{enumerate}
        \item If $E \subseteq X$, we have $\mu^*(E) \leq \mu^+(E)$, with equality iff there exists $A \in \calM^*$ with $A \supseteq E$ and $\mu^*(A) = \mu^*(E)$.

        \item If $\mu^*$ is induced from a premeasure, then $\mu^* = \mu^+$.

        \item If $X = \{0,1\}$, there exists an outer measure $\mu^*$ on $X$ such that $\mu^* \neq \mu^+$.
    \end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
    \item Recall that the definition of $\mu^+$ means that
    %
    \begin{equation*}
        \mu^+(E)
            = \inf \set[\bigg]{ \sum_{n=1}^\infty \overline\mu(A_n) }{ A_n \in \calM^*, E \subseteq \bigunion_{n\in\naturals} A_n },
    \end{equation*}
    %
    and that we by definition of $\overline\mu$ can replace $\overline\mu$ with $\mu^*$. For any such sequence $(A_n)$ we have
    %
    \begin{equation*}
        \mu^*(E)
            \leq \mu^* \Bigl( \bigunion_{n\in\naturals} A_n \Bigr)
            \leq \sum_{n=1}^\infty \mu^*(A_n)
            = \sum_{n=1}^\infty \overline\mu(A_n).
    \end{equation*}
    %
    And since $\mu^+(E)$ is the infimum of all such sums, we have $\mu^*(E) \leq \mu^+(E)$.

    Next assume that there is an $A \in \calM^*$ with $E \subseteq A$ such that $\mu^*(A) = \mu^*(E)$. Using the sequence $A_1 = A$ and $A_n = \emptyset$ for $n > 1$ in the definition of $\mu^+$ yields
    %
    \begin{equation*}
        \mu^+(E)
            \leq \overline\mu(A)
            = \mu^*(A)
            = \mu^*(E).
    \end{equation*}
    %
    Hence $\mu^+(E) = \mu^*(E)$ as desired.

    Conversely, assuming that $\mu^*(E) = \mu^+(E)$ we have
    %
    \begin{equation*}
        \mu^*(E)
            = \inf \set[\bigg]{ \sum_{n=1}^\infty \mu^*(A_n) }{ A_n \in \calM^*, E \subseteq \bigunion_{n\in\naturals} A_n }.
    \end{equation*}
    %
    Given $\epsilon > 0$, choose a sequence $(A_n)$ such that
    %
    \begin{equation*}
        \mu^* \Bigl( \bigunion_{n\in\naturals} A_n \Bigr)
            \leq \sum_{n=1}^\infty \mu^*(A_n)
            \leq \mu^*(E) + \epsilon,
    \end{equation*}
    %
    and let $B_\epsilon = \bigunion_{n\in\naturals} A_n$. Letting $A = \bigintersect_{k\in\naturals} B_{1/k} \in \calM^*$ we thus have $\mu^*(A) \leq \mu^*(E)$.

    \item Assume that $\mu^*$ is induced from a premeasure on an algebra $\calA$, and let $E \subseteq X$. Recall that $\calA$ consists of $\mu^*$-measurable sets, so $\sigma(\calA) \subseteq \calM^*$. For $n \in \naturals$ choose, in accordance with Exercise~1.18(a), a set $A_n \in \calA_\sigma$ with $E \subseteq A_n$ such that $\mu^*(A_n) \leq \mu^*(E) + 1/n$. Letting $A = \bigintersect_{n\in\naturals} A_n$ we have $E \subseteq A$ and $\mu^*(A) \leq \mu^*(E)$. The other inequality is obvious, so $\mu^*(A) = \mu^*(E)$, and part (a) implies that $\mu^*(E) = \mu^+(E)$ as desired.
\end{solutionsec}
\end{solution}


\begin{exerciseframed*}[21]
    Let $\mu^*$ be an outer measure induced from a premeasure and $\overline\mu$ the restriction of $\mu^*$ to the $\mu^*$-measurable sets. Then $\overline\mu$ is saturated.
\end{exerciseframed*}

\begin{solution}
	Let $\calA$ denote the algebra on which the premeasure in question is defined, and denote by $\calM^*$ the $\sigma$-algebra of $\mu^*$-measurable sets. Recall that $\calA \subseteq \calM^*$.
	
	Let $E \subseteq X$ be locally measurable. It suffices to show that
	%
	\begin{equation*}
		\mu^*(F)
        \geq \mu^*(F \intersect E) + \mu^*(F \intersect E^c)
	\end{equation*}
	%
	for all $F \subseteq X$ with $\mu^*(F) < \infty$. Given $\epsilon   > 0$, Exercise~1.18(a) yields a set $A \in \calA_\sigma$ such that $\mu^*(A) \leq \mu^*(F) + \epsilon$. Then $\mu^*(A) < \infty$, and so $E \intersect A \in \calM^*$. It follows that
	%
	\begin{align*}
		\mu^*(F) + \epsilon
        \geq \mu^*(A)
        &= \mu^*(A \intersect (E \intersect A))
		+ \mu^*(A \intersect (E \intersect A)^c) \\
        &= \mu^*(A \intersect E) + \mu^*(A \intersect E^c) \\
        &\geq \mu^*(F \intersect E) + \mu^*(F \intersect E^c),
	\end{align*}
	%
	and hence $E \in \calM^*$. Thus $\overline\mu$ is saturated.
\end{solution}


\begin{exerciseframed*}[22]
    Let $(X,\calM,\mu)$ be a measure space, $\mu^*$ the outer measure induced by $\mu$ according to (1.12), $\calM^*$ the $\sigma$-algebra of $\mu^*$-measurable sets, and $\overline\mu = \mu^*|_{\calM^*}$.
    %
    \begin{enumerate}
        \item If $\mu$ is $\sigma$-finite, then $\overline\mu$ is the completion of $\mu$.
        \item In general, $\overline\mu$ is the saturation of the completion of $\mu$.
    \end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
    \item Let $\overline\calM$ be the $\sigma$-algebra from Theorem~1.9 (namely, the $\sigma$-algebra generated by the sets in $\calM$ along with all $\mu$-null sets). This is clearly the smallest $\sigma$-algebra on which there can exist a complete extension of $\mu$, so since $\overline\mu$ is also a complete extension of $\mu$, we must have $\overline\calM \subseteq \calM^*$. Theorem~1.9 yields the uniqueness of a complete extension of $\mu$ on $\overline\calM$, so it suffices to show that $\calM^* \subseteq \overline\calM$.
    
    Now assume that $\mu$ is $\sigma$-finite, and let $E \in \calM^*$. Then also $E^c \in \calM^*$, and Exercise~1.18(c) ensures the existence of sets $B,D \in \calM_{\sigma\delta} = \calM$ with $E \subseteq B$ and $E^c \subseteq D$ such that
    %
    \begin{equation*}
        \mu^*(B \setminus E) = 0
        \quad \text{and} \quad
        \mu^*(E \setminus D^c) = \mu^*(D \setminus E^c) = 0.
    \end{equation*}
    %
    It follows that
    %
    \begin{equation*}
        \mu(B \setminus D^c)
            \leq \mu^*(B \setminus E) + \mu^*(E \setminus D^c)
            = 0,
    \end{equation*}
    %
    so $E \setminus D^c$ is a $\mu$-null set. Thus $E = D^c \union (E \setminus D^c)$ is a union of a set in $\calM$ and a $\mu$-null set, and hence $E \in \overline\calM$.

    \item Let $\hat\mu$ denote the completion of $\mu$ on $\overline\calM$, and let $\widetilde\calM$ denote the $\sigma$-algebra of locally $\hat\mu$-measurable sets. First we show that $\widetilde\calM = \calM^*$, so let $E \in \widetilde\calM$. To show that $E$ is $\mu^*$-measurable it suffices to show that
    %
    \begin{equation*}
        \mu^*(F)
            \geq \mu^*(F \intersect E) + \mu^*(F \intersect E^c)
    \end{equation*}
    %
    for all $F \subseteq X$ with $\mu^*(F) < \infty$. Calculations identical to the ones in the solution to Exercise~1.21 show this.

    Conversely, let $E \in \calM^*$ and consider $A \in \overline\calM$ with $\hat\mu(A) < \infty$. Then also $A \in \calM^*$, so $E \intersect A \in \calM^*$. The argument at the beginning of part (a) showed that $\overline\mu$ is an extension of $\hat\mu$, so $\mu^*(E \intersect A) = \hat\mu(E \intersect A) < \infty$. The same argument as in part (a), only now using Exercise~1.18(b) instead of (c), shows that $E \intersect A \in \overline\calM$, and so $E \in \widetilde\calM$.

    Finally, let $\tilde\mu$ denote the saturation of $\hat\mu$. We show that $\overline\mu = \tilde\mu$. Since the completion of $\mu$ on $\overline\calM$ is unique, the two measures must agree here. Instead let $E \in \widetilde\calM \setminus \overline\calM$. By definition of $\tilde\mu$ we must then have $\tilde\mu(E) = \infty$. On the other hand, we just showed (for $E \intersect A$ instead of $E$) that $\mu^*(E) < \infty$ implies $E \in \overline\calM$. Since we have assumed that this is not the case, we must have $\overline\mu(E) = \mu^*(E) = \infty$. Thus $\overline\mu = \tilde\mu$.
\end{solutionsec}
\end{solution}


\section{Borel Measures on the Real Line}

\begin{exerciseframed*}[25]
    If $E \subseteq \reals$, the following are equivalent.
    %
    \begin{enumerate}
        \item $E \in \calM_\mu$.
        \item $E = V \setminus N_1$ where $V$ is a $G_\delta$ set and $\mu(N_1) = 0$.
        \item $E = H \union N_2$ where $H$ is an $F_\sigma$ set and $\mu(N_2) = 0$.
    \end{enumerate}
\end{exerciseframed*}

\begin{solution}
	Folland proves this claim when $\mu(E) < \infty$, so assume that $\mu(E) = \infty$. Since $\mu$ is $\sigma$-finite, there is a sequence $(E_n)_{n\in\naturals}$ in $\calM_\mu$ with $\mu(E_n) < \infty$ for all $n \in \naturals$ and $E = \bigunion_{n\in\naturals} E_n$. Then there are sequences $(H_n)$ of $F_\sigma$ sets and $(N_n)$ of null sets such that $E_n = H_n \union N_n$. Then $H = \bigunion_{n\in\naturals} H_n$ is also an $F_\sigma$ set and $N = \bigunion_{n\in\naturals} N_n$ a null set, and $E = H \union N$.

	Applying this to $E^c$ yields a similar decomposition $E^c = H \union N$. But then $E = H^c \setminus N$, and $H^c$ is a $G_\delta$ set.
\end{solution}





\chapter{Integration}

\section{Measurable Functions}

\begin{exerciseframed*}[10]
    The following implications are valid iff the measure $\mu$ is complete:
    %
    \begin{enumerate}
        \item If $f$ is measurable and $f = g$ $\mu$-a.e., then $g$ is measurable.
        \item If $f_n$ is measurable for $n \in \naturals$ and $f_n \to f$ $\mu$-a.e., then $f$ is measurable.
    \end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
    \item Assume that $\mu$ is complete, and let $f,g \colon (X,\calE,\mu) \to (Y,\calF)$ be functions from a measure space to a measurable space where $f$ is $(\calE,\calF)$-measurable. Let $N = \{f \neq g\}$ and assume that $\mu(N) = 0$. Given $B \in \calF$ we must show that $g\preim(B) \in \calE$. But notice that
    %
    \begin{equation*}
        g\preim(B)
            = f\preim(B) \union \{ f \not\in B, g \in B \} \setminus \{ f \in B, g \not\in B \},
    \end{equation*}
    %
    and that the latter two sets are subsets of $N$, hence measurable. Thus $g\preim(B)$ is also measurable.

    % Conversely, let $\mu$ be a measure on a measurable space $(X,\calE)$ that is not complete, and let $N \subseteq X$ be a non-measurable $\mu$-null set. Then $\indicator{N} = 0$ $\mu$-a.e., but $\indicator{N}$ is not measurable.

	Conversely, let $N \subseteq X$ be a $\mu$-null set. Then $\indicator{N} = 0$ $\mu$-a.e., so $\indicator{N}$ and therefore $N$ is measurable. Hence $\mu$ is complete.

    \item Assume that $\mu$ is complete, and consider the set $A$ of points $x \in X$ such that $f_n(x)$ does not converge to $f(x)$. Then $f_n \indicator{A^c} \to f \indicator{A^c}$ pointwise everywhere, so Proposition~2.7 (or Corollary~2.9) implies that $f \indicator{A^c}$ is measurable. By assumption we have $\mu(A) = 0$, so $f \indicator{A^c} = f$ $\mu$-a.e. and part (a) implies that $f$ is measurable.
    
    Conversely, let $N \subseteq X$ be a $\mu$-null set and consider the sequence $(f_n)_{n\in\naturals}$ with $f_n = 0$ for all $n \in \naturals$. This converges $\mu$-a.e. to $\indicator{N}$ so $N$ is measurable. Hence $\mu$ is complete.
\end{solutionsec}
\end{solution}


\addtocounter{section}{5}
\section{Integration in Polar Coordinates}

\begin{remark}
	We give a heuristic derivation of the radial measure $\rho_d$. Let $\dif A$ be an area element in $\reals^2$. In polar coordinates $(r,\theta)$ this has a radial size of $\dif r$ and an angular size of $r \dif\theta$. Notice that since $\theta$ is an angle, we multiply it by the distance $r$ from the origin. Hence
	%
	\begin{equation*}
		\dif A
			= r \dif\theta \dif r
			= (r \dif r) \dif\theta.
	\end{equation*}
	%
	Going up one dimension we introduce another angular coordinate $\phi$, which contributes a factor $f(\theta,\phi) r \dif\phi$ to the volume element, where $f$ is some function of the angular coordinates. Similarly when going up yet another dimension: this again introduces a factor $r$, and now $f$ is a function of yet another angular coordinate. In $d$ dimensions we have $d-1$ angular coordinates $\theta_1, \ldots, \theta_{d-1}$, so the volume element is on the form
	%
	\begin{equation*}
		\dif V
			= f(\theta_1, \ldots, \theta_{d-1}) r^{d-1} \dif r \dif\theta_1 \cdots \dif\theta_{d-1}.
	\end{equation*}
	%
	The radial part is thus $r^{d-1} \dif r$, so it makes sense to define the radial measure $\rho_d$ on $(0,\infty)$ by
	%
	\begin{equation*}
		\rho_d(E)
			= \int_E r^{d-1} \dif r.
	\end{equation*}
\end{remark}


\chapter{Signed Measures and Differentiation}

\section{Signed Measures}

\begin{exerciseframed*}[2]
	If $\nu$ is a signed measure, $E$ is $\nu$-null iff $\abs\nu(E) = 0$. Also, if $\nu$ and $\mu$ are signed measures, $\nu \perp \mu$ iff $\abs\nu \perp \mu$ iff $\nu^+ \perp \mu$ and $\nu^- \perp \mu$.
\end{exerciseframed*}

\begin{solution}
	Assume that $E$ is $\nu$-null, and let $P \union N$ be a Hahn decomposition for $\nu$. Then
	%
	\begin{equation*}
		\nu^+(E) = \nu(E \intersect P) = 0,
	\end{equation*}
	%
	since $E \intersect P \subseteq E$. Similarly we get $\nu^-(E) = 0$, so $\abs{\nu}(E) = 0$. Conversely, assume that $\abs{\nu}(E) = 0$. Then $\nu^\pm(F) = 0$ for all measurable $F \subseteq E$, and so $\nu(F) = 0$.

	The other claims follow directly from the above.
\end{solution}


\begin{exerciseframed*}[3]
	Let $\nu$ be a signed measure on $(X,\calM)$.
	%
	\begin{enumerate}
		\item $L^1(\nu) = L^1(\abs\nu)$.
		\item If $f \in L^1(\nu)$,
		%
		\begin{equation*}
			\abs[\bigg]{ \int f \dif\nu }
				\leq \int \abs{f} \dif\abs\nu.
		\end{equation*}
		
		\item If $E \in \calM$,
		%
		\begin{equation*}
			\abs\nu(E)
				= \sup\set[\bigg]{ \abs[\bigg]{\int_E f \dif\nu} }{ \abs{f} \leq 1 }.
		\end{equation*}
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item This follows directly from the definition of $L^1(\nu)$.
	
	\item For $f \in L^1(\nu)$ we have
	%
	\begin{equation*}
		\abs[\bigg]{ \int f \dif\nu }
			= \abs[\bigg]{ \int f \dif\nu^+ - \int f \dif\nu^- }
			\leq \int \abs{f} \dif\nu^+ + \int \abs{f} \dif\nu^-
			= \int \abs{f} \dif\abs\nu,
	\end{equation*}
	%
	since $\abs{\nu} = \nu^+ + \nu^-$.

	\item If $\abs{f} \leq 1$, then
	%
	\begin{equation*}
		\abs[\bigg]{ \int_E f \dif\nu }
			\leq \int_E \abs{f} \dif\abs{\nu}
			\leq \abs{\nu}(E),
	\end{equation*}
	%
	showing one inequality. For the other inequality, let $P \union N$ be a Hahn decomposition for $\nu$, and let $f = \indicator{P} - \indicator{N}$. Then
	%
	\begin{align*}
		\int_E f \dif\nu
			&= \int_E (\indicator{P} - \indicator{N}) \dif\nu^+
			   - \int_E (\indicator{P} - \indicator{N}) \dif\nu^- \\
			&= \nu^+(E \intersect P) - \nu^+(E \intersect N)
			   - \nu^-(E \intersect P) + \nu^-(E \intersect N) \\
			&= \nu^+(E) + \nu^-(E)
			 = \abs\nu(E).
	\end{align*}
\end{solutionsec}
\end{solution}


\begin{exerciseframed*}[4]
	If $\nu$ is a signed measure and $\lambda, \mu$ are positive measures such that $\nu = \lambda - \mu$, then $\lambda \geq \nu^+$ and $\mu \geq \nu^-$.
\end{exerciseframed*}

\begin{solution}
	Let $P \union N$ be a Hahn decomposition for $\nu$. Then
	%
	\begin{equation*}
		\nu^+(E)
			= \nu(E \intersect P)
			= \lambda(E \intersect P) - \mu(E \intersect P)
			\leq \lambda(E \intersect P)
			\leq \lambda(E),
	\end{equation*}
	%
	and similarly for $\nu^-$.
\end{solution}


\begin{exerciseframed*}[5]
	If $\nu_1, \nu_2$ are signed measures that both omit the value $\infty$ or $-\infty$, then $\abs{\nu_1 + \nu_2} \leq \abs{\nu_1} + \abs{\nu_2}$.
\end{exerciseframed*}

\begin{solution}
	First notice that
	%
	\begin{equation*}
		\nu_1 + \nu_2
			= (\nu_1^+ + \nu_2^+) - (\nu_1^- + \nu_2^-),
	\end{equation*}
	%
	so by the previous exercise we have
	%
	\begin{equation*}
		\abs{\nu_1 + \nu_2}
			= (\nu_1 + \nu_2)^+ + (\nu_1 + \nu_2)^+
			\leq (\nu_1^+ + \nu_2^+) + (\nu_1^- + \nu_2^-)
			= \abs{\nu_1} + \abs{\nu_2}.
	\end{equation*}
\end{solution}


\begin{exerciseframed*}[7]
	Suppose that $\nu$ is a signed measure on $(X,\calM)$ and $E \in \calM$.
	%
	\begin{enumerate}
		\item $\nu^+(E) = \sup\set{\nu(F)}{F \in \calM, F \subseteq E}$ and $\nu^-(E) = -\inf\set{\nu(F)}{F \in \calM, F \subseteq E}$.

		\item We have
		%
		\begin{equation*}
			\abs\nu(E)
				= \sup\set[\bigg]{ \sum_{i=1}^n \abs{\nu(E_i)} }
				        { n \in \naturals, \text{$E_1, \ldots, E_n$ disjoint}, \bigunion_{i=1}^n E_i = E }.
		\end{equation*}
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item We prove the first identity, the second is proved similarly. Denote the supremum on the right-hand side by $\mu(E)$, and let $P \union N$ be a Hahn decomposition for $\nu$. Since $E \intersect P \subseteq E$ we have
	%
	\begin{equation*}
		\nu^+(E)
			= \nu(E \intersect P)
			\leq \mu(E).
	\end{equation*}
	%
	Furthermore, for $F \in \calM$ with $F \subseteq E$ notice that
	%
	\begin{equation*}
		\nu(F)
			= \nu^+(F) - \nu^-(F)
			\leq \nu^+(F)
			\leq \nu^+(E),
	\end{equation*}
	%
	showing that $\mu(E) \leq \nu^+(E)$.

	\item Denote the quantity on the right-hand side by $\rho(E)$, and let $P \union N$ be a Hahn decomposition for $\nu$. The disjoint union $E = (E \intersect P) \union (E \intersect N)$ yields
	%
	\begin{equation*}
		\rho(E)
			\geq \abs{\nu(E \intersect P)} + \abs{\nu(E \intersect N)}
			= \nu^+(E) + \nu^-(E)
			= \abs\nu(E). 
	\end{equation*}
	%
	Conversely, let $E_1, \ldots, E_n$ be disjoint sets in $\calM$ such that $\bigunion_{i=1}^n E_i = E$. For $i = 1, \ldots, n$ we have
	%
	\begin{equation*}
		\abs{\nu(E_i)}
			= \abs{ \nu^+(E_i) - \nu^-(E_i) }
			\leq \nu^+(E_i) + \nu^-(E_i)
			= \abs\nu(E_i),
	\end{equation*}
	%
	implying that
	%
	\begin{equation*}
		\sum_{i=1}^n \abs{\nu(E_i)}
			\leq \sum_{i=1}^n \abs\nu(E_i)
			= \abs\nu(E).
	\end{equation*}
	%
	It follows that $\rho(E) \leq \abs\nu(E)$.
\end{solutionsec}
\end{solution}


\chapter{Point Set Topology}

\setcounter{section}{3}
\section{Compact Spaces}

\begin{exerciseframed*}[38]
	Suppose that $(X,\calT)$ is a compact Hausdorff space and $\calT'$ is another topology on $X$. If $\calT'$ is strictly stronger than $\calT$, then $(X,\calT')$ is Hausdorff but not compact. If $\calT'$ is strictly weaker than $\calT$, then $(X,\calT')$ is compact but not Hausdorff.
\end{exerciseframed*}

\begin{solution}
	First assume that $\calT \subseteq \calT'$, and further assume that $(X,\calT')$ is compact. If $U \in \calT'$ we then must show that $U \in \calT$. Notice that $X \setminus U$ is closed in $\calT'$ and hence compact, so it is also compact in the weaker topology $\calT$. Since $\calT$ is Hausdorff $X \setminus U$ is closed, but then $U \in \calT$.

	Next assume that $\calT' \subseteq \calT$ and that $(X,\calT')$ is Hausdorff. Let $U \in \calT$ and fix $x \in U$. For each $y \not\in U$ there is a pair of disjoint neighbourhoods $V_y$ of $x$ and $W_y$ of $y$ in $\calT'$. The collection $\set{W_y}{y \not\in U}$ is an open cover of $X \setminus U$, and since this is closed in $\calT$ it is also compact, so there is a finite subcover $W_{y_1}, \ldots, W_{y_n}$. Letting $V_x = V_{y_1} \intersect \cdots \intersect V_{y_n}$, the set $V_x$ is completely contained in $U$. But then $U$ is the union of the sets $V_x$ as $x$ ranges over $U$, so $U$ is a union of elements from $\calT'$. Hence it is itself open in $\calT'$.
\end{solution}


\section{Locally Compact Hausdorff Spaces}

\begin{exerciseframed*}[49]
	Let $X$ be a compact Hausdorff space and $E \subseteq X$.
	%
	\begin{enumerate}
		\item If $E$ is open, then $E$ is locally compact in the relative topology.
		\item b
		\item c
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item Since every point in $X$ has a compact neighbourhood (namely $X$ itself), $X$ is locally compact. So if $x \in E$ and $E$ is open, then Proposition~4.30 yields a compact neighbourhood $K \subseteq E$ of $x$. But then $K$ is also a compact neighbourhood of $x$ in $E$, showing that $E$ is locally compact.
	
	\item b
	\item c
\end{solutionsec}
\end{solution}


\begin{remark}
	\label{rem:one-point-compactification}
	Let $X$ be a compact Hausdorff space, and let $x_0 \in X$ be any point in $X$. Exercise~4.49(a) then shows that $X \setminus \{x_0\}$ is locally compact, so we may consider the one-point compactification $(X \setminus \{x_0\})^*$. We claim that $(X \setminus \{x_0\})^* \cong X$.
	
	Denote the adjoined point by $\infty$ and consider the inclusion map $i \colon X \setminus \{x_0\} \to X$ extended to $(X \setminus \{x_0\})^*$ by letting $i(\infty) = x_0$. This is a bijection, and restricted to $X \setminus \{x_0\}$ it is a homeomorphism onto its image. We claim that $i$ is itself a homeomorphism, and since both its domain and codomain are compact Hausdorff it suffices to show that it is continuous. So let $U \subseteq X$ be open. If $x_0 \not\in U$ then $i\preim(U) = (i|_{X \setminus \{x_0\}})\preim(U)$, which is open in $X \setminus \{x_0\}$, hence open in $(X \setminus \{x_0\})^*$. Otherwise of $x_0 \in U$ then $\infty \in i\preim(U)$, and we need to show that $i\preim(U)^c = i\preim(U^c)$ is compact. But $U^c$ is a closed, hence compact, subset of $X \setminus \{0\}$, so its preimage under the homeomorphism $i|_{X \setminus \{x_0\}}$ is also compact.
\end{remark}


\begin{exerciseframed*}[52]
	The one-point compactification of $\reals^n$ is homeomorphic to the sphere $\sphere^n$.
\end{exerciseframed*}

\begin{solution}
	Let $x_0 \in \sphere^n$ be any point on the sphere. By stereographic projection, $\sphere^n \setminus \{x_0\}$ and $\reals^n$ are homeomorphic. But then \cref{rem:one-point-compactification} shows that
	%
	\begin{equation*}
		(\reals^n)^*
			\cong (\sphere^n \setminus \{x_0\})^*
			\cong \sphere
	\end{equation*}
	%
	as desired.
\end{solution}


\addtocounter{section}{1}
\section{The Stone--Weierstrass Theorem}

\begin{remark}
	Notice that we never use the Hausdorff assumption in the proof of the Stone--Weierstrass theorem. However, if $X$ is a topological space and there exists a family $\calF$ of functions in $C(X)$ or $C(X,\reals)$ that separates points in $X$, then $X$ is automatically Hausdorff: For let $x \neq y$ be points in $X$, and let $f \in \calF$ be such that $f(x) \neq f(y)$. Choosing disjoint neighbourhoods $U_x$ and $U_y$ of $x$ and $y$ respectively, $f\preim(U_x)$ and $f\preim(U_y)$ are disjoint neighbourhoods of $x$ and $y$ in $X$. Hence $X$ is Hausdorff.

	In other words, Hausdorff is not a necessary condition in the statement of the theorem, but rather follows from the other hypotheses.

	In contrast, the compactness hypothesis is used very explicitly in the proof of Lemma~4.49.
\end{remark}

\begin{exerciseframed*}[66]
	Let $1 - \sum_{n=1}^\infty c_n t^n$ be the Maclaurin series for $(1 - t)^{1/2}$.
	%
	\begin{enumerate}
		\item The series converges absolutely and uniformly on compact subsets of $(-1,1)$, as does the termwise differentiated series $- \sum_{n=1}^\infty n c_n t^{n-1}$. Thus, if $f(t) = 1 - \sum_{n=1}^\infty c_n t^n$, then $f'(t) = - \sum_{n=1}^\infty n c_n t^{n-1}$.

		\item By explicit calculation, $f(t) = -2(1-t) f'(t)$, from which it follows that $(1-t)^{-1/2} f(t)$ is constant. Since $f(0) = 1$, $f(t) = (1-t)^{1/2}$.
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item We first compute the coefficients $c_n$. If $g(t) = (1 - t)^{1/2}$, then we claim that
	%
	\begin{equation*}
		g^{(n)}(t)
			= - \frac{(2n-3)(2n-5) \cdots (3)(1)}{2^n} (1-t)^{-(2n-1)/2}
	\end{equation*}
	%
	for $n \in \naturals$ and $t \in (-1,1)$. Indeed, this follows easily by induction. Hence
	%
	\begin{equation*}
		c_n
			= \frac{1}{n!} g^{(n)}(0)
			= - \frac{1}{n!} \frac{(2n-3)(2n-5) \cdots (3)(1)}{2^n}.
	\end{equation*}
	%
	Now let $\rho \in (0,1)$. Then
	%
	\begin{equation*}
		\abs[\bigg]{\frac{c_{n+1}\rho^{n+1}}{c_n \rho^n}}
			= \frac{n!}{(n+1)!} \frac{2n-1}{2} \rho
			= \frac{2n-1}{2n} \rho
			\xrightarrow[n \to \infty]{} \rho
			< 1.
	\end{equation*}
	%
	The ratio test then implies that the series $\sum_{n=1}^\infty c_n \rho^n$ converges, so it follows from the Weierstrass M-test that the series $1 - \sum_{n=1}^\infty c_n t^n$ converges absolutely and uniformly on the interval $[-\rho,\rho]$, and hence on all compact subsets of $(-1,1)$. We similarly find that
	%
	\begin{equation*}
		\abs[\bigg]{\frac{(n+1)c_{n+1}\rho^n}{nc_n \rho^{n-1}}}
			= \frac{n!}{(n+1)!} \frac{n+1}{n} \frac{2n-1}{2} \rho
			= \frac{n+1}{n} \frac{2n-1}{2n} \rho
			\xrightarrow[n \to \infty]{} \rho
			< 1,
	\end{equation*}
	%
	so the series $- \sum_{n=1}^\infty n c_n t^{n-1}$ also converges as claimed.

	\item Notice that
	%
	\begin{align*}
		-2(1-t) f'(t)
			&= 2(1-t) \sum_{n=1}^\infty n c_n t^{n-1}
			 = 2 \sum_{n=1}^\infty n c_n t^{n-1} - 2 \sum_{n=1}^\infty n c_n t^n \\
			&= 2 \sum_{n=0}^\infty (n+1) c_{n+1} t^n - 2 \sum_{n=1}^\infty n c_n t^n \\
			&= 2 \sum_{n=0}^\infty \bigl( (n+1) c_{n+1} - n c_n \bigr) t^n.
	\end{align*}
	%
	A short calculation shows that $(n+1) c_{n+1} - n c_n = c_n/2$, so the above equals $f(t)$ as claimed. Thus we have
	%
	\begin{equation*}
		\frac{\dif}{\dif t} (1-t)^{-1/2} f(t)
			= (1-t)^{-1/2} f'(t) + \frac{1}{2} (1-t)^{-3/2} f(t)
			= 0,
	\end{equation*}
	%
	showing that $(1-t)^{-1/2} f(t)$ is constant. But $f(0) = 1$, so it follows that $f(t) = (1-t)^{1/2} = g(t)$.
\end{solutionsec}
\end{solution}


\chapter{Elements of Functional Analysis}

\section{Normed Vector Spaces}

\begin{remark}
	We give a slightly different proof of Proposition~5.2.

	Clearly if $T \colon X \to Y$ is continuous, then it is continuous at $0$. And if this is so, then there is a $\delta > 0$ such that $\norm{h} \leq \delta$ implies $\norm{Th} \leq 1$, for $h \in X$. For all $x \in X$ we thus have
	%
	\begin{equation*}
		\norm{Tx}
			= \frac{\norm{x}}{\delta} \norm[\bigg]{T \biggl( \delta \frac{x}{\norm{x}} \biggr) }
			\leq \delta\inv \norm{x},
	\end{equation*}
	%
	so $T$ is bounded.

	We let
	%
	\begin{equation*}
		\norm{T}
			= \sup \set[\big]{\norm{Tx}}{x \in X, \norm{x} \leq 1}
	\end{equation*}
	%
	If $T$ is bounded, then clearly $\norm{T} < \infty$. If conversely $\norm{T} < \infty$, then
	%
	\begin{equation*}
		\norm{Tx}
			= \norm[\bigg]{T \frac{x}{\norm{x}} } \, \norm{x}
			\leq \norm{T} \, \norm{x}
	\end{equation*}
	%
	for all $x \neq 0$, so $T$ is bounded. Furthermore, if $K > 0$ is such that $\norm{Tx} \leq K \norm{x}$ for all $x \in X$, then $\norm{Tx} \leq K$ whenever $\norm{x} \leq 1$. But then $\norm{T} \leq K$.
\end{remark}


\begin{remarkbreak}[Riesz' lemma]
	The statement of the lemma is as follows:
	%
	\begin{displaytheorem}
		Let $X$ be a normed vector space and $M$ a proper closed subspace of $X$. For $\alpha \in (0,1)$ there exists an $x \in X$ with $\norm{x} = 1$ such that
		%
		\begin{equation*}
			\inf_{m \in M} \norm{x - m} \geq \alpha.
		\end{equation*}
	\end{displaytheorem}
	%
	Since the quotient norm on $X/M$ is given by $\norm{x+M} = \inf_{m \in M} \norm{x-m}$, this is precisely the statement of Exercise~5.12(b) [TODO: reference].

	In Exercise~5.19(b) [TODO: reference] we use this to show that an infinite-dimensional normed vector space is not locally compact. It is easy to show that this is equivalent to the closed unit ball $\closure{B}_1(0)$ being compact.
	
	Conversely, every normed space $(X, \norm{\,\cdot\,})$ of dimension $d < \infty$ is locally compact: Choose a linear isomorphism $T \colon \complex^d \to X$ and let it induce a norm $\norm{\,\cdot\,}'$ on $X$. With this norm $T$ is an isometry, hence a homeomorphism, so the local compactness of $\complex^d$ is transferred to $(X, \norm{\,\cdot\,}')$. But all norms on finite-dimensional vector spaces are equivalent, so $(X, \norm{\,\cdot\,})$ is also locally compact.

	This equivalence of local compactness and finite-dimensionality generalises to Hausdorff topological vector spaces. This is known as \emph{F.\,Riesz' theorem}.
\end{remarkbreak}


\begin{exerciseframed*}[3]
	If $Y$ is complete, so is $\calB(X,Y)$.
\end{exerciseframed*}

\begin{solution}
	We prove the following lemma:
	%
	\begin{displaytheorem}
		Let $X$ and $Y$ be normed spaces, and let $(T_n)_{n\in\naturals}$ be a sequence in $\calB(X,Y)$. If $(T_n)$ is Cauchy in the operator norm and converges to some $T \colon X \to Y$ in the strong operator topology, then $T \in \calB(X,Y)$ and $T_n \to T$ in the operator norm.
	\end{displaytheorem}
	%
	The map $T$ is clearly linear. Choose $N \in \naturals$ such that $m,n \geq N$ implies that $\norm{T_n - T_m} \leq \epsilon$. For $x \in X$ and $n \geq N$ we then have
	%
	\begin{equation*}
		\norm{(T_n - T)x}
			= \lim_{m\to\infty} \norm{(T_n - T_m) x}
			\leq \limsup_{m\to\infty} \norm{T_n - T_m} \, \norm{x}
			\leq \epsilon \norm{x}.
	\end{equation*}
	%
	Hence $T_n - T$ is bounded, and then so is $T$. Furthermore, $\norm{T_n - T} \leq \epsilon$, so $T_n \to T$ in the operator norm.

	To prove the initial claim it thus suffices to produce, given a Cauchy sequence $(T_n)_{n\in\naturals}$, a map $T \colon X \to Y$ such that $\slim_{n\to\infty} T_n = T$. But notice that we for $x \in X$ we have
	%
	\begin{equation*}
		\norm{T_n x - T_m x}
			\leq \norm{T_n - T_m} \, \norm{x}
	\end{equation*}
	%
	for $m,n \in \naturals$, so $(T_n x)_{n\in\naturals}$ is a Cauchy sequence in $Y$. Defining $T \colon X \to Y$ by $Tx = \lim_{n\to\infty} T_n x$, $T$ is the strong limit of $T_n$ by construction.
\end{solution}


\begin{exerciseframed*}[4]
	If $X$ and $Y$ are normed spaces, the map $(T,x) \mapsto Tx$ is continuous from $\calB(X,Y) \prod X$ to $Y$.
\end{exerciseframed*}

\begin{solution}
	If $T,S \in \calB(X,Y)$ and $x,y \in X$, then
	%
	\begin{equation*}
		\norm{Tx - Sy}
			\leq \norm{Tx - Ty} + \norm{Ty - Sy}
			\leq \norm{T} \, \norm{x - y} + \norm{T - S} \, \norm{y}.
	\end{equation*}
	%
	The claim follows.

	Notice that this proof is identical to the proof that multiplication in a Banach algebra is continuous, but the Banach inequality is replaced with the inequality $\norm{Tx} \leq \norm{T} \, \norm{x}$. The proof is also almost identical to the proof that multiplication on $\reals$ or $\complex$ is continuous, except here we have the \emph{equality} $\abs{xy} = \abs{x} \, \abs{y}$.
\end{solution}


\begin{exerciseframed*}[6]
	Suppose that $X$ is a finite-dimensional vector space. Let $(e_1, \ldots, e_d)$ be a basis for $X$, and define $\norm{\sum_{i=1}^d a_i e_i}_1 = \sum_{i=1}^d \abs{a_i}$.
	%
	\begin{enumerate}
		\item $\norm{\,\cdot\,}_1$ is a norm on $X$.
		\item The map $T \colon (a_1, \ldots, a_d) \mapsto \sum_{i=1}^d a_i e_i$ is continuous from $\bbK^d$ with the usual Euclidean topology to $X$ with the topology defined by $\norm{\,\cdot\,}_1$.
		\item The set $S = \set{x \in X}{\norm{x}_1 = 1}$ is compact in the topology defined by $\norm{\,\cdot\,}_1$.
		\item All norms on $X$ are equivalent.
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item This is obvious.
	
	\item If we equip $\bbK^d$ with the $1$-norm, then $T$ is an isometry and thus continuous (in fact a homeomorphism since it is surjective).

	\item Since the unit sphere in $\bbK^d$ (with respect to the $1$-norm) is compact and $T$ is continuous, $S$ is also compact.

	\item If $\norm{\,\cdot\,}$ is any norm on $X$, we need to find $C_1,C_2 > 0$ such that
	%
	\begin{equation}
		\label{eq:norm-equivalence}
		C_1 \norm{x}_1
			\leq \norm{x}
			\leq C_2 \norm{x}_1
	\end{equation}
	%
	for all $x \in X$. This is obvious for $x = 0$, and if $x \neq 0$ we may divide through by $\norm{x}_1$. The claim is then that
	%
	\begin{equation*}
		C_1
			\leq \norm{x}
			\leq C_2
	\end{equation*}
	%
	for all $x \in X$ with $\norm{x}_1 = 1$, i.e. all $x \in S$. We first show that $\norm{\,\cdot\,}$ is continuous with respect to $\norm{\,\cdot\,}_1$. For $x = \sum_{i=1}^d a_i e_i$ and $y = \sum_{i=1}^d b_i e_i$ in $X$ we have
	%
	\begin{equation*}
		\norm{x-y}
			= \norm[\bigg]{ \sum_{i=1}^d (a_i - b_i) e_i }
			\leq \sum_{i=1}^d \abs{a_i - b_i} \, \norm{e_i}
			\leq \norm{x-y}_1 \max_{1 \leq i \leq d} \norm{e_i}.
	\end{equation*}
	%
	Continuity of $\norm{\,\cdot\,}$ now follows from the reverse triangle inequality. (In fact, this calculation also proves the second inequality of \cref{eq:norm-equivalence}, but we give a second argument below.)

	Since $\norm{\,\cdot\,}$ is continuous and $S$ is compact with respect to $\norm{\,\cdot\,}_1$, $\norm{\,\cdot\,}$ has a minimum and maximum on $S$. That is, there exist $x_0, x_1 \in S$ such that
	%
	\begin{equation*}
		\norm{x_0}
			\leq \norm{x}
			\leq \norm{x_1}
	\end{equation*}
	%
	for all $x \in S$. And since both of $x_0$ and $x_1$ are nonzero then so are their norms, proving the claim.
\end{solutionsec}
\end{solution}


\begin{exerciseframed*}[9]
	Let $C^k([0,1])$ be space of functions on $[0,1]$ possessing continuous derivatives up to order $k$ on $[0,1]$, including onesided derivatives at the endpoints.
	%
	\begin{enumerate}
		\item If $f \in C([0,1])$, then $f \in C^k([0,1])$ iff $f$ is $k$ times continuously differentiable on $(0,1)$ and $f^{(j)}(0+) = \lim_{x \downarrow 0} f^{(j)}(x)$ and $f^{(j)}(1-) = \lim_{x \uparrow 1} f^{(j)}(x)$ exist for $j \leq k$.
		\item $\norm{f} = \sum_{j=0}^k \norm{f^{(j)}}_\infty$ is a norm on $C^k([0,1])$ that makes $C^k([0,1])$ into a Banach space.
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item The \enquote{only if} part is obvious. Conversely, we show by induction in $j$ that $f \in C^j([0,1])$ for $j = 0, \ldots, k$. This is true for $j = 0$ by assumption, so assume that it is true for some $j$. For $x \in (0,1)$ there is a $\xi \in (0,x)$ such that $f^{(j)}(x) - f^{(j)}(0) = f^{(j+1)}(\xi)(x-0)$. It follows that
	%
	\begin{equation*}
		\frac{ f^{(j)}(x) - f^{(j)}(0) }{x-0}
			= f^{(j+1)}(\xi)
			\xrightarrow[x \downarrow 0]{} f^{(j+1)}(0+).
	\end{equation*}
	%
	Thus $f^{(j)}$ has a one-sided derivative at $0$, and since the derivative is precisely the limit $f^{(j+1)}(0+)$, this also shows that $f^{(j+1)}$ is continuous at $0$. Similarly at $1$, so $f \in C^{j+1}([0,1])$ as desired.

	\item Let $(f_n)_{n\in\naturals}$ be a sequence in $C^1([0,1])$ converging to a function $f$, such that the sequence $(f_n')$ converges uniformly in $C([0,1])$ to a function $g$. Let $\epsilon > 0$, and choose $N \in \naturals$ such that $n \geq N$ implies that $\norm{f_n' - g}_\infty < \epsilon$. For $n \geq N$ and fixed $x \in [0,1]$ we then have
	%
	\begin{equation*}
		\abs[\bigg]{ \int_0^x f_n'(t) \dif t - \int_0^x g(t) \dif t }
			\leq \int_0^x \abs{f_n'(t) - g(t)} \dif t
			\leq \epsilon x.
	\end{equation*}
	%
	It follows that
	%
	\begin{equation*}
		f(x) - f(0)
			= \lim_{n\to\infty} \bigl( f_n(x) - f_n(0) \bigr)
			= \lim_{n\to\infty} \int_0^x f'(t) \dif t
			= \int_0^x g(t) \dif t.
	\end{equation*}
	%
	Thus we see that $f \in C^1([0,1])$ with $f' = g$.

	Now let $(f_n)_{n\in\naturals}$ be a Cauchy sequence in $C^k([0,1])$. Then the sequences $(f_n^{(j)})$ are Cauchy sequences in $C([0,1])$ for $j = 0, \ldots, k$, and so the sequences have uniform limits. But then we are in the situation above, so it follows by induction that $f_n^{(j)} \to f^{(j)}$ uniformly for all $j$. Hence $f_n \to f$ in $C^k([0,1])$, so this is a Banach space.
\end{solutionsec}
\end{solution}


\begin{remark}
	As an application of the above we consider the following: Let $D \colon C^k([0,1]) \to C^{k-1}([0,1])$ be the differential operator $f \mapsto f'$. We claim that this is bounded with respect to the above norm. For $f \in C^k([0,1])$ we have
	%
	\begin{equation*}
		\norm{Df}
			= \sum_{j=0}^{k-1} \norm{(Df)^{(j)}}_\infty
			= \sum_{j=0}^{k-1} \norm{f^{(j+1)}}_\infty
			= \sum_{j=1}^k \norm{f^{(j)}}_\infty
			\leq \norm{f}.
	\end{equation*}
	%
	The usual counterexamples to the boundedness of $D$ on e.g. $(C^1([0,1]), \norm{\,\cdot\,}_\infty)$ do not work here. The norm $\norm{\,\cdot\,}$ in effect takes into account the fact that functions that take on similar values may have derivatives that vary wildly.
\end{remark}


\begin{exerciseframed*}[12]
	Let $X$ be a normed vector space and $M$ a proper closed subspace of $X$.
	%
	\begin{enumerate}
		\item $\norm{x + M} = \inf_{m \in M} \norm{x + m}$ is a norm on $X/M$.
		\item For any $\epsilon > 0$ there exists $x \in X$ such that $\norm{x} = 1$ and $\norm{x + M} \geq 1 - \epsilon$.
		\item The projection map $\pi \colon X \to X/M$ has norm $1$.
		\item If $X$ is complete, so is $X/M$.
		\item The topology defined by the quotient norm is the quotient topology.
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item Assume first that $M$ is not necessarily closed. For $x \in X$ and $\alpha \in \bbK \setminus \{0\}$ we have
	%
	\begin{equation*}
		\norm{\alpha(x + M)}
			= \norm{\alpha x + M}
			= \inf_{m \in M} \norm{\alpha x + m}
			= \abs{\alpha} \inf_{m \in M} \norm{x + \alpha\inv m}
			= \abs{\alpha} \, \norm{x + M},
	\end{equation*}
	%
	where the last equality follows since every element in $M$ is on the form $\alpha\inv m$ for some $m \in M$. Hence the map $\norm{\,\cdot\,}$ on $X/M$ is absolutely homogeneous.

	For the triangle inequality, let $x,y \in X$ and $m,m' \in M$. Then
	%
	\begin{equation*}
		\norm{(x + M) + (y + M)}
			= \norm{(x + y) + M}
			\leq \norm{x + y + m + m'}
			\leq \norm{x + m} + \norm{y + m'},
	\end{equation*}
	%
	which implies that
	%
	\begin{equation*}
		\norm{(x + M) + (y + M)}
			\leq \norm{x + M} + \norm{y + M}
	\end{equation*}
	%
	as desired. Hence $\norm{\,\cdot\,}$ is a seminorm on $X/M$ for any $M$.

	Finally assume that $M$ is closed, and let $x \in X \setminus M$. Then there exists an $r > 0$ such that $B_r(x) \intersect M = \emptyset$, so $\norm{x - m} \geq r$ for all $m \in M$. Hence $\norm{x + M} \geq r > 0$ as desired.
	
	\item Let $\epsilon > 0$, and pick some $y \in X \setminus M$. By definition of the quotient norm there exists an $m \in M$ such that
	%
	\begin{equation*}
		\frac{\norm{y+M}}{\norm{y-m}}
			\geq 1 - \epsilon.
	\end{equation*}
	%
	Letting $x = (y-m)/\norm{y-m}$ we have $\norm{x} = 1$ and
	%
	\begin{equation*}
		\norm{x + M}
			= \norm[\bigg]{ \frac{y-m}{\norm{y-m}} + M }
			= \frac{\norm{y + M}}{\norm{y-m}}
			\geq 1 - \epsilon
	\end{equation*}
	%
	as desired.
	
	\item For any $x \in X$ we have $\norm{x + M} \leq \norm{x + 0}$, so $\norm{\pi} \leq 1$. But given $\epsilon > 0$, (b) shows that $\norm{x + M} \geq 1 - \epsilon$ for some $x \in X$ with $\norm{x} = 1$, so $\norm{\pi} \geq 1 - \epsilon$. Since $\epsilon$ was arbitrary, $\norm{\pi} \geq 1$.

	\item We use Theorem~5.1. Let $\sum_{n=1}^\infty \xi_n$ be an absolutely convergent series with terms in $X/M$. For each $n \in \naturals$ there exists an $x_n \in X$ such that $\xi_n = x_n + M$ and such that $\norm{x_n} \leq \norm{\xi_n} + 2^{-n}$. It follows that
	%
	\begin{equation*}
		\sum_{n=1}^\infty \norm{x_n}
			\leq \sum_{n=1}^\infty \bigl( \norm{\xi_n} + 2^{-n} \bigr)
			= \sum_{n=1}^\infty \norm{\xi_n} + 1
			< \infty,
	\end{equation*}
	%
	so by completeness of $X$, Theorem~5.1 implies that the series $\sum_{n=1}^\infty x_n$ converges to some $x \in X$. Since $\pi$ is continuous, it follows that $\sum_{n=1}^\infty x_n + M$ converges to $x + M$, so $X/M$ is complete by Theorem~5.1.

	\item The projection map $\pi \colon X \to X/M$ is continuous in the norm topology by (c), so the quotient topology is coarser than the norm topology. To prove the opposite inclusion we show that $\pi$ is a quotient map. It suffices to show that $\pi$ is open. To this end we prove the following lemma:
	%
	\begin{displaytheorem}
		Let $X$ be a (semi)normed vector space and $M$ a subspace of $X$. For $r > 0$ and $x \in X$ we have
		%
		\begin{equation*}
			B_r(\pi(x)) = \pi\bigl( B_r(x) \bigr).
		\end{equation*}
	\end{displaytheorem}
	%
	By homogeneity it suffices to consider the case $x = 0$. By (b) we have $\norm{\pi} = 1$, so for $y \in B_r(0)$ we have
	%
	\begin{equation*}
		\norm{y + M}
			\leq \norm{y}
			< r,
	\end{equation*}
	%
	and so $y + M \in B_r(0 + M)$, proving the inclusion \enquote{$\supseteq$}. For the opposite inclusion, for $y + M \in B_r(0 + M)$ we have
	%
	\begin{equation*}
		\inf_{m \in M} \norm{y + m}
			= \norm{y + M}
			< r,
	\end{equation*}
	%
	so there is an $m \in M$ such that $\norm{y+m} < r$. Hence $y+m \in B_r(0)$, and so
	\begin{equation*}
		y + M
			= \pi(y + m)
			\in \pi\bigl( B_r(0) \bigr),
	\end{equation*}
	%
	proving the inclusion \enquote{$\subseteq$}.

	In particular, the image of an open ball under $\pi$ is an open ball. It now follows that $\pi$ is open, since every open set is a union of open balls.
\end{solutionsec}
\end{solution}


\begin{exerciseframed*}[15]
	Suppose that $X$ and $Y$ are normed vector spaces and $T \in \calB(X,Y)$. Let $\calN(T) = \set{x \in X}{Tx = 0}$.
	%
	\begin{enumerate}
		\item $\calN(T)$ is a closed subspace of $X$
		\item Let $M$ be a closed subspace of $X$ contained in $\calN(T)$. There is a unique bounded $\tilde{T} \colon X/M \to Y$ such that $T = \tilde{T} \circ \pi$, where $\pi \colon X \to X/M$ is the projection. Moreover, $\norm{\tilde{T}} = \norm{T}$.
	\end{enumerate}
\end{exerciseframed*}
%
Our version of [TODO: link] (b) is more general than Folland's.

\begin{solution}
\begin{solutionsec}
	\item This is obvious since $T$ is continuous.
	
	\item Basic linear algebra yields a unique (not necessarily bounded) linear map $\tilde{T} \colon X/M \to Y$ such that $T = \tilde{T} \circ \pi$. To compute its norm we use the lemma from the solution to [TODO: Exercise 5.12(e)]. Let $B = B_1(0) \subseteq X$ and $\tilde{B} = \pi(B) = B_1(0 + M) \subseteq X/M$. Then
	%
	\begin{align*}
		\norm{\tilde{T}}
			&= \sup\set[\big]{ \norm{\tilde{T}\xi} }{\xi \in \tilde{B}} \\
			&= \sup\set[\big]{ \norm{\tilde{T}\xi} }{\xi \in \pi(B)} \\
			&= \sup\set[\big]{ \norm{\tilde{T}(\pi(x))} }{x \in B} \\
			&= \sup\set[\big]{ \norm{Tx} }{x \in B} \\
			&= \norm{T}.
	\end{align*}
	%
	Here we use the fact that for an operator $T \colon X \to Y$ it suffices to consider $x \in X$ with $\norm{x} < 1$ in computing its norm: For assume that $\norm{x} = 1$, and let $\epsilon_n = 1 - 1/n$. Then $\norm{\epsilon_n x} < 1$, and
	%
	\begin{equation*}
		\norm{Tx}
			= \frac{1}{\epsilon_n} \norm{T(\epsilon_n x)}
			\leq \frac{1}{\epsilon_n} \sup\set[\big]{ \norm{Ty} }{y \in B}
			\xrightarrow[n\to\infty]{} \sup\set[\big]{ \norm{Ty} }{y \in B}.
	\end{equation*}
	%
	Hence $\norm{T} \leq \sup\set{ \norm{Ty} }{y \in B}$, and the opposite equality is obvious.
\end{solutionsec}
\end{solution}


\section{Linear Functionals}

\newcommand{\cat}[1]{\mathcal{#1}}
\newcommand{\scat}[1]{\mathbf{#1}} % category supposed to be small
\newcommand{\ncat}[1]{\mathbf{#1}} % named categories like Set, Top

\newcommand{\catNor}{\ncat{Nor}}
\newcommand{\catBan}{\ncat{Ban}}
\newcommand{\catSet}{\ncat{Set}}


\begin{exerciseframed*}[18]
	Let $X$ be a normed vector space.
	%
	\begin{enumerate}
		\item If $M$ is a closed subspace and $x \in X \setminus M$, then $M + \complex x$ is closed.
		\item Every finite-dimensional subspace of $X$ is closed.
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item Let $(y_n)_{n\in\naturals}$ and $(\lambda_n)_{n\in\naturals}$ be sequences in $M$ and $\complex$ respectively such that $y_n + \lambda_n x$ converges to some $z \in X$. By Theorem~5.8(b) there is a $\phi \in X^*$ such that $\phi(x) \neq 0$ and $\phi|_M = 0$. Applying $\phi$ to the above sequence yields
	%
	\begin{equation*}
		\phi(z)
			= \lim_{n\to\infty} \bigl( \phi(y_n) + \lambda_n \phi(x) \bigr)
			= \bigl( \lim_{n\to\infty} \lambda_n \bigr) \phi(x),
	\end{equation*}
	%
	which implies that $\lambda_n$ converges to $\phi(z) / \phi(x)$. The sequence $(y_n)$ is then also convergent with limit in $M$, and so
	%
	\begin{equation*}
		\lim_{n\to\infty} \bigl( y_n + \lambda_n x \bigr)
			= \lim_{n\to\infty} \biggl( y_n + \frac{\phi(z)}{\phi(x)} x \biggr)
			= \lim_{n\to\infty} y_n + \frac{\phi(z)}{\phi(x)} x,
	\end{equation*}
	%
	which lies in $M + \complex x$ as desired.

	\item We give two different arguments. If $U$ is a finite-dimensional subspace of $X$ and $(e_1, \ldots, e_d)$ is a basis for $U$, then $U = \sum_{i=1}^d \complex e_i$. Since $\{0\}$ is a closed subspace of $X$, the desired result follows from the above by induction.
	
	We may also argue as follows: It suffices to show that $U$ is complete. To this end, let $(x_n)_{n\in\naturals}$ be a Cauchy sequence in $U$ and write $x_n = \lambda_{n1} e_1 + \cdots + \lambda_{nd} e_d$. We claim that the sequence $(\lambda_{ni})_{n\in\naturals}$ is a Cauchy sequence for all $i$. For the norm $\norm{\,\cdot\,}$ on $U$ inherited from $X$ is equivalent to the $1$-norm $\norm{\,\cdot\,}_1$, so
	%
	\begin{equation*}
		\norm{x_m - x_n}
			\geq C \norm{x_m - x_n}_1
			\geq C \abs{\lambda_{mi} - \lambda_{ni}}
	\end{equation*}
	%
	for some $C > 0$. Since $\complex$ is complete, the sequence $(\lambda_{ni})_{n\in\naturals}$ converges to some $\lambda_i \in \complex$. Letting $x = \lambda_1 e_1 + \cdots + \lambda_d e_d$, we claim that $x_n \to x$ as $n \to \infty$. This follows since (choosing the $e_i$ to be unit vectors)
	%
	\begin{align*}
		\norm{x_n - x}
			&= \norm{(\lambda_{n1} - \lambda_1)e_1 + \cdots + (\lambda_{nd} - \lambda_d)e_d} \\
			&\leq \abs{\lambda_{n1} - \lambda_1} + \cdots + \abs{\lambda_{nd} - \lambda_d},
	\end{align*}
	%
	and the right-hand side converges to zero.
\end{solutionsec}
\end{solution}


\begin{exerciseframed*}[19]
	Let $X$ be an infinite-dimensional normed vector space.
	%
	\begin{enumerate}
		\item There is a sequence $(x_n)_{n\in\naturals}$ in $X$ such that $\norm{x_n} = 1$ for all $n \in \naturals$ and $\norm{x_n - x_m} \geq 1/2$ for $m \neq n$.
		\item $X$ is not locally compact.
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item First pick any unit vector $x_1 \in X$. By Exercise~5.18 the subspace $M_1 = \complex x_1$ is closed, so Exercise~5.12(b) yields a unit vector $x_2 \not\in M_1$ such that $\norm{x_2 + M_1} \geq 1/2$. Since $x_1 \in M_1$ we in particular have $\norm{x_2 - x_1} \geq 1/2$. Similarly, letting $M_2 = M_1 + \complex x_2$ we get a unit vector $x_3 \not\in M_2$ with $\norm{x_3 + M_2} \geq 1/2$. Single both $x_1$ and $x_2$ lie in $M_2$ we have $\norm{x_3 - x_1} \geq 1/2$ and $\norm{x_3 - x_2} \geq 1/2$. Continuing this process yields the desired sequence. [TODO: Exercise references]
	
	\item Assume towards a contradiction that $X$ is locally compact. Then $0 \in X$ has a compact neighbourhood $K$, and by multiplying with an appropriate scalar we may assume that $K$ contains the closed unit ball $\closure{B}_1(0)$. Thus $K$ contains the sequence $(x_n)$ constructed in part (a). Now Theorem~0.25 implies that $K$ is sequentially compact, so $(x_n)$ has a convergent subsequence. But this is impossible since $\norm{x_n - x_m} \geq 1/2$ for $m \neq n$, so $X$ is not locally compact.
\end{solutionsec}
\end{solution}


\begin{remark}
	\label{rem:isometry-norm}
	Let $X$ and $Y$ be normed spaces, and let $T \in \calB(X,Y)$. If $T$ is an isometry, then clearly $\norm{T} = 1$. It is easy to think that the converse is also true, perhaps if $T$ is also assumed to be boundedly invertible, but this is not the case: For instance, equip $\reals^2$ with the supremum norm\footnote{In \cref{rem:normed-space-categories} we will see that this makes $\reals^2$ into the categorical product of $\reals$ and $\reals$. This has no relevance to the present discussion, as far as I know.} and consider the operator $S \colon \reals^2 \to \reals^2$ given by $S(x,y) = (x,y/2)$. Then $\norm{S} = 1$, and $S\inv(x,y) = (x,2x)$ is also bounded with $\norm{S\inv} = 2$. But $S$ is clearly not an isometry, since e.g.
	%
	\begin{equation*}
		\norm{S(0,2)}_\infty
			= \norm{(0,1)}_\infty
			= 1
			\neq 2
			= \norm{(0,2)}_\infty.
	\end{equation*}
	%
	The problem is already apparent, in that the norm of $S\inv$ is \emph{not} $1$, so $S\inv$ cannot be an isometry. This motivates the following result:
	%
	\begin{displaytheorem}
		Let $T \in \calB(X,Y)$ be a boundedly invertible map between normed spaces such that $\norm{T} = \norm{T\inv} = 1$. Then $T$ is an isometry.
	\end{displaytheorem}
	%
	For if $x \in X$ and $y = Tx$, then
	%
	\begin{equation*}
		\norm{Tx}
			\leq \norm{T} \, \norm{x}
			= \norm{x}
			= \norm{T\inv y}
			\leq \norm{T\inv} \, \norm{y}
			= \norm{y}
			= \norm{Tx},
	\end{equation*}
	%
	so $\norm{Tx} = \norm{x}$.
\end{remark}


\begin{remarkbreak}[The categories $\catNor$ and $\catNor_1$ of normed spaces]
	\label{rem:normed-space-categories}
	A map $f \colon (S,\rho) \to (T,\delta)$ between metric spaces having the property that
	%
	\begin{equation*}
		\delta(f(x), f(y))
			\leq \rho(x, y)
	\end{equation*}
	%
	for all $x,y \in S$ is variously called a \emph{short map}, a \emph{metric map}, \emph{nonexpansive} or \emph{-expanding}, a \emph{weak contraction}, or just a Lipschitz function with Lipschitz constant $1$. We consider the category $\catNor_1$ whose objects are normed spaces and whose arrows are linear maps that are also short maps. Notice that a linear map $T \colon X \to Y$ between normed spaces is short just when $\norm{T} \leq 1$. Hence $\catNor_1$ is a subcategory of the category $\catNor$ of normed spaces and bounded linear maps.
	
	A bounded linear map $T \colon X \to Y$ is an isomorphism in $\catNor$ just when it is boundedly invertible. In $\catNor_1$ the situation is slightly more complicated: The map $S$ in \cref{rem:isometry-norm} is a short map but its inverse is not short. Hence the isomorphisms in $\catNor_1$ are the boundedly invertible maps with short inverses, and this latter assumption cannot be removed. Furthermore, we claim that in this case $T$ is in fact an isometry. If $T$ has a bounded inverse $T\inv$, then
	%
	\begin{equation*}
		1 = \norm{\id_X}
			= \norm{T\inv T}
			\leq \norm{T\inv} \, \norm{T}.
	\end{equation*}
	%
	Hence if both $T$ and $T\inv$ are short maps, then $\norm{T} = \norm{T\inv} = 1$. But then \cref{rem:isometry-norm} implies that $T$ is an isometry. Conversely, surjective isometries\footnote{An isometry is in particular injective, so surjective isometries are bijective. The inverse is also clearly bounded.} are clearly short maps whose inverses are also short, so any surjective isometry is an isomorphism in $\catNor_1$.

	If $X$ and $Y$ are normed spaces we may equip the Cartesian product $X \prod Y$ with different norms, two of which are of particular importance here, namely the supremum norm\footnote{We denote any norm on a vector space other than $X \times Y$ by $\norm{\,\cdot\,}$, relying on context to distinguish.} $\norm{(x,y)}_\infty = \max\{ \norm{x}, \norm{y} \}$ and the $1$-norm $\norm{(x,y)}_1 = \norm{x} + \norm{y}$. We reserve the notation $X \prod Y$ for the Cartesian product equipped with the supremum norm, and we use the notation $X \oplus Y$ when we equip the Cartesian product with the $1$-norm.

	We claim that $X \prod Y$ is a categorical product of $X$ and $Y$. First notice that the projections $\pi_X \colon X \prod Y \to X$ and $\pi_Y \colon X \prod Y \to Y$ are indeed short maps. For instance,
	%
	\begin{equation*}
		\norm{\pi_X(x,y)}
			= \norm{x}
			\leq \max \bigl\{ \norm{x}, \norm{y} \bigr\}
			= \norm{(x,y)}_\infty.
	\end{equation*}
	%
	Given short linear maps $T_X \colon Z \to X$ and $T_Y \colon Z \to Y$, the map $T \colon Z \to X \prod Y$ given by $Tz = (T_X z, T_Y z)$ is certainly linear. It is also short, for
	%
	\begin{equation*}
		\norm{Tz}_\infty
			= \norm{(T_X z, T_Y z)}_\infty
			= \max \bigl\{ \norm{T_X z}, \norm{T_Y z} \bigr\}
			\leq \norm{z}.
	\end{equation*}
	%
	Notice that the $1$-norm would not in general make $T$ into a short map, but that the supremum norm is in some sense natural: Bounding a pair $(x,y)$ just means bounding \emph{both} $x$ and $y$ separately. Furthermore, it clearly makes the diagram
	%
	\begin{equation*}
        \begin{tikzcd}
            && X \\
            Z
                \ar[r, "T"]
                \ar[urr, "T_X", bend left]
                \ar[drr, "T_Y", bend right, swap]
            & X \prod Y
                \ar[ur, "\pi_X", swap]
                \ar[dr, "\pi_Y"] \\
            && Y
        \end{tikzcd}
    \end{equation*}
	%
	commute, and it is (even in $\catSet$) unique with this property, so $X \prod Y$ is indeed a product of $X$ and $Y$.

	Next we claim that $X \oplus Y$ is a coproduct of $X$ and $Y$. The inclusion maps $i_X \colon X \to X \oplus Y$ and $i_Y \colon Y \to X \oplus Y$ are given by $i_X(x) = (x,0)$ and $i_Y(0,y)$. Notice that e.g.
	%
	\begin{equation*}
		\norm{i_X(x)}_1
			= \norm{(x,0)}_1
			= \norm{x} + \norm{0}
			= \norm{x},
	\end{equation*}
	%
	so the inclusion maps are isometries, in particular short maps. Furthermore, if $S_X \colon X \to W$ and $S_Y \colon Y \to W$ are short linear maps, we define a map $S \colon X \oplus Y \to W$ by $S(x,y) = S_X x + S_Y y$. This is then clearly linear, and it is also short since
	%
	\begin{equation*}
		\norm{S(x,y)}
			= \norm{S_X x + S_Y y}
			\leq \norm{S_X x} + \norm{S_Y y}
			\leq \norm{x} + \norm{y}
			= \norm{(x,y)}_1.
	\end{equation*}
	%
	Again notice that the supremum norm would not make $S$ into a short map. But the $1$-norm is natural in the sense that elements of $X \oplus Y$ are to be thought of, in some sense, \emph{sums} of elements in $X$ and $Y$. Hence the norm of such a sum is (naturally) the sum of the norms. Finally, it clearly makes the diagram
	%
	\begin{equation*}
        \begin{tikzcd}
            X
                \ar[dr, "i_X"]
                \ar[drr, "S_X", bend left] \\
            & X \oplus Y
                \ar[r, "S"]
            & W \\
            Y
                \ar[ur, "i_Y", swap]
                \ar[urr, "S_Y", bend right, swap]
        \end{tikzcd}
    \end{equation*}
	%
	commute, and so $X \oplus Y$ is a coproduct of $X$ and $Y$ as claimed.

	For completeness we note that the categories $\catBan$ and $\catBan_1$ of Banach spaces and, respectively, bounded and short linear maps are full subcategories of $\catNor$ and $\catNor_1$. If $X$ and $Y$ are Banach spaces, then so are $X \times Y$ and $X \oplus Y$: If $((x_n,y_n))_{n\in\naturals}$ is a Cauchy sequence in either, then $(x_n)$ and $(y_n)$ are Cauchy in $X$ and $Y$ respectively, converging to $x \in X$ and $y \in X$. We then have
	%
	\begin{equation*}
		\norm{(x_n,y_n) - (x,y)}_\infty
			= \norm{(x_n - x, y_n - y)}_\infty
			= \max \bigl\{ \norm{x_n - x}, \norm{y_n - y} \bigr\},
	\end{equation*}
	%
	which goes to zero as $n \to \infty$. We similarly have
	%
	\begin{equation*}
		\norm{(x_n,y_n) - (x,y)}_1
			= \norm{x_n - x} + \norm{y_n - y},
	\end{equation*}
	%
	which similarly goes to zero. In either case $(x_n,y_n)$ converges to $(x,y)$. Thus $X \times Y$ and $X \oplus Y$ are also a product and coproduct in $\catBan$ and $\catBan_1$.

	Furthermore, if $X$ and $Y$ are Banach spaces and $T \in \calB(X,Y)$ is bijective, then the Open Mapping Theorem implies that $T\inv$ is bounded. The isomorphisms in $\catBan$ are thus simply the bijections. However, the example in \cref{rem:isometry-norm} shows that an isomorphism in $\catBan$ with norm $1$ might have an inverse with norm greater than $1$. Thus there does not seem to be a simpler characterisation of the isomorphisms of $\catBan_1$ than the bijections $T$ such that both $T$ and $T\inv$ have norm $1$.
\end{remarkbreak}


\begin{exerciseframed*}[21]
	If $X$ and $Y$ are normed vector spaces, define $\alpha \colon X^* \oplus Y^* \to (X \prod Y)^*$ by
	%
	\begin{equation*}
		\alpha(\phi,\psi)(x,y) = \phi(x) + \psi(y).
	\end{equation*}
	%
	Then $\alpha$ is an isometric isomorphism.
\end{exerciseframed*}
%
This says that the dual functor $(-)^* \colon \catNor \to \catNor$ sends products to coproducts. [TODO: Is this more properly a functor on $\catNor_1$? And what about the dual space, can it contain functionals with norm $>1$?]

\begin{solution}
	We first show that $\alpha$ is surjective, so let $\chi \in (X \prod Y)^*$ and define $\phi(x) = \chi(x,0)$ and $\psi(y) = \chi(0,y)$. These are then bounded linear functionals: e.g.,
	%
	\begin{equation*}
		\abs{ \phi(x) }
			= \abs{ \chi(x,0) }
			\leq \norm{\chi} \, \norm{(x,0)}
			= \norm{\chi} \, \norm{x},
	\end{equation*}
	%
	and $\alpha(\phi,\psi) = \phi(x) + \psi(y) = \chi(x,y)$, so $\alpha$ is surjective.

	Next we show that $\alpha$ is an isometry. We have
	%
	\begin{align*}
		\abs{ \alpha(\phi,\psi)(x,y) }
			&= \abs{ \phi(x) + \psi(y) } \\
			&\leq \abs{\phi(x)} + \abs{\psi(y)} \\
			&\leq \norm{\phi} \, \norm{x} + \norm{\psi} \, \norm{y} \\
			&\leq \bigl( \norm{\phi} + \norm{\psi} \bigr) \max \bigl\{ \norm{x}, \norm{y} \bigr\} \\
			&= \norm{(\phi,\psi)} \, \norm{(x,y)},
	\end{align*}
	%
	so $\norm{\alpha(\phi,\psi)} \leq \norm{(\phi,\psi)}$. Next, let $x \in X$ and $y \in Y$ be unit vectors. Theorem~5.8(b) then furnishes $\phi \in X^*$ and $\psi \in Y^*$ with $\norm{\phi} = \norm{\psi} = 1$, $\phi(x) = \norm{x} = 1$ and $\psi(y) = \norm{y} = 1$. We thus have
	%
	\begin{align*}
		\abs{ \alpha(\phi,\psi)(x,y) }
			&= \abs{ \phi(x) + \psi(y) } \\
			&= \norm{x} + \norm{y} \\
			&= 2 \cdot 1 \\
			&= \bigl( \norm{\phi} + \norm{\psi} \bigr) \max \bigl\{ \norm{x}, \norm{y} \bigr\} \\
			&= \norm{(\phi,\psi)} \, \norm{(x,y)},
	\end{align*}
	%
	showing that $\norm{\alpha(\phi,\psi)} \geq \norm{(\phi,\psi)}$. In total, $\alpha$ is an isometry. Hence it is also injective and thus an isomorphism.
\end{solution}


\begin{remark}
	Let $X$ be a vector space over a field $k$, and let $X^*$ be the algebraic dual of $X$. If $U$ is a subspace of $X$, then the \emph{annihilator} of $U$ is the subspace $U^0$ of $X^*$ consisting of those functionals $\phi$ such that $\phi(u)$ for all $u \in U$. We use $U^0$ to describe the algebraic dual $U^*$ of $U$.

	Let $i_U \colon U \to X$ be the inclusion map, and consider its pullback
	%
	\begin{equation*}
		\beta = i_U^* \colon X^* \to U^*
	\end{equation*}
	%
	given by precomposition with $i_U$. This is surjective, since if $\psi \in U^*$ then we may extend this to a linear functional on $X$ by letting $\psi(v) = 0$ for all $v \in V$, where $V$ is any complement of $U$ in $X$. Furthermore, a functional $\phi \in X^*$ lies in the kernel of $\beta$ just if $\phi$ vanishes on $U$, i.e. if $\phi \in U^0$. The first isomorphism theorem then yields a linear isomorphism
	%
	\begin{equation*}
		\tilde{\beta} \colon X^*/U^0 \to U^*.
	\end{equation*}
\end{remark}


\begin{exerciseframed*}[23]
	Suppose that $X$ is a Banach space. If $M$ is a closed subspace of $X$ and $N$ is a closed subspace of $X^*$, let $M^0 = \set{\phi \in X^*}{\phi|_M = 0}$ and $N^\perp = \set{x \in X}{\text{$\phi(x) = 0$ for all $\phi \in N$}}$.
	%
	\begin{enumerate}
		\item $M^0$ and $N^\perp$ are closed subspaces of $X^*$ and $X$, respectively.
		\item $(M^0)^\perp = M$ and $(N^\perp)^0 \supseteq N$. If $X$ is reflexive, $(N^\perp)^0 = N$.
		\item c
		\item Define $\beta \colon X^* \to M^*$ by $\beta(\phi) = \phi_M$; then $\beta$ induces a map $\tilde{\beta} \colon X^*/M^0 \to M^*$, and $\tilde{\beta}$ is an isometric isomorphism.
	\end{enumerate}
\end{exerciseframed*}

\begin{solution}
\begin{solutionsec}
	\item First assume that $X$ is a normed vector space over $\bbK$, and assume that $M$ and $N$ are merely (not necessarily closed) \emph{subsets} of $X$ and $X^*$. Then $M^0$ and $N^\perp$ are clearly subspaces. Consider the inclusion map $i_M \colon M \to X$ and its pullback $\beta = i_M^* \colon X^* \to M^*$. The former clearly has norm $1$, so for $\phi \in X^*$ the composition $\phi \circ i_M$ is bounded. It follows that
	%
	\begin{equation*}
		\norm{\beta(\phi)}
			= \norm{\phi \circ i_M}
			\leq \norm{\phi} \, \norm{i_M}
			= \norm{\phi}
	\end{equation*}
	%
	so $\beta$ is bounded. But notice that $M^0 = \ker\beta$, so $M^0$ is closed. Furthermore, notice that
	%
	\begin{equation*}
		N^\perp
			= \bigintersect_{\phi \in N} \ker\phi,
	\end{equation*}
	%
	so $N^\perp$ is an intersection of closed sets, hence is closed.

	\item Let $x \in M$. Then $\phi(x) = 0$ for all $\phi \in M^0$, and so $x \in (M^0)^\perp$. Conversely, assume that $M$ is now a closed subspace of $M$, and assume that $x \not\in M$. Theorem~5.8(b) then yields a functional $\phi \in X^*$ such that $\phi_M = 0$ and $\phi(x) \neq 0$. But this means that $\phi \in M^0$ and that $x \not\in (M^0)^\perp$.

	Furthermore, if $\phi \in N$ then clearly $\phi(x)$ for all $x \in N^\perp$, so $\phi \in (N^\perp)^0$ (even if $N$ is neither closed or a subspace).
	
	TODO: $X$ reflexive.

	\item c

	\item Since $\ker\beta = M^0$ and $\beta$ is surjective, $\tilde{\beta}$ is a linear isomorphism, and it is bounded since $\beta$ is. It remains to be shown that it is an isometry. First let $\phi \in X^*$ and notice that
	\begin{equation*}
		\norm{ \tilde{\beta}(\phi + M^0) }
			= \norm{\beta(\phi)}
			= \norm{\phi \circ i_M}
			\leq \norm{\phi},
	\end{equation*}
	%
	since $\norm{i_M} = 1$ (unless $M = 0$, but in this case the claim is trivial). Since $\norm{\phi + M^0}$ is the infimum of $\norm{\psi}$ over all $\psi \in X^*$ such that $\psi + M^0 = \phi + M^0$, it follows that $\norm{ \tilde{\beta}(\phi + M^0) } \leq \norm{\phi + M^0}$. For the opposite inequality, consider the seminorm
	%
	\begin{equation*}
		p(x) = \norm{\tilde{\beta}(\phi + M^0)} \, \norm{x}
	\end{equation*}
	%
	on $X$. For $x \in M$ we have
	%
	\begin{equation*}
		\abs{\phi(x)}
			= \abs{\beta(\phi)(x)}
			= \abs{\tilde{\beta}(\phi + M^0)(x)}
			\leq p(x),
	\end{equation*}
	%
	so the Hahn--Banach theorem furnishes a $\psi \in X^*$ that extends $\phi|_M$ and satisfies\footnote{In the real case this follows since $p$ is a seminorm.} $\abs{\psi} \leq p$, i.e. $\norm{\psi} \leq \norm{\tilde{\beta}(\phi + M^0)}$. In other words, $\psi|_M = \phi|_M$ or equivalently $\psi + M^0 = \phi + M^0$. It follows that
	%
	\begin{equation*}
		\norm{\phi + M^0}
			= \norm{\psi + M^0}
			\leq \norm{\psi}
			\leq \norm{\tilde{\beta}(\phi + M^0)}.
	\end{equation*}
	%
	In total, $\tilde{\beta}$ is an isometry.
\end{solutionsec}
\end{solution}


\addtocounter{section}{1}
\section{Topological vector spaces}

\begin{remarkbreak}[Induced vector space topologies]
	Let $X$ be a vector space and $Y$ a normed vector space over $\bbK$, and let $\calL(X,Y)$ be the vector space of all linear maps $X \to Y$. Any collection $\calF \subseteq \calL(X,Y)$ of course induces an initial topology on $X$. On the other hand, each map $T \in \calF$ defines a seminorm $p_T$ on $X$ given by $p_T(x) = \norm{Tx}$. We claim that the initial topology on $X$ induced by $\calF$ is the same as the seminorm topology induced by the family $\{p_T\}_{T \in \calF}$ of seminorms as in Theorem~5.14.

	To see this, notice that, for $x_0 \in X$ and $\epsilon > 0$,
	%
	\begin{align*}
		U_{x_0 T \epsilon}
			&= \set{ x \in X }{ p_T(x-x_0) < \epsilon } \\
			&= \set[\big]{ x \in X }{ \norm{Tx-Tx_0} < \epsilon } \\
			&= T\preim \bigl( B_\epsilon(Tx_0) \bigr).
	\end{align*}
	%
	The initial topology on $X$ induced by $\calF$ is generated by the sets on the right-hand side.\footnote{This is clear if each $T$ is surjective. But $T \colon X \to Y$ is continuous iff the corresponding map with codomain $T(X)$ is continuous, so it suffices to consider balls in $Y$ with centres in $T(X)$.} On the other hand, the seminorm topology induced by $\{p_T\}_{T \in \calF}$ is generated by the sets on the left-hand side. Hence the two topologies agree.

	The most common application of the above is when $U$ is a subspace of $\calL(X,Y)$ and $\calF$ is the set of evaluation maps $\ev_x \colon U \to Y$ given by $\ev_x(T) = Tx$ for $x \in X$. It is easy to show that the evaluation maps are in fact linear. Since the evaluation maps obviously separate points in $\calL(X,Y)$, the resulting topology is Hausdorff (hence $T_3$ since topological groups are automatically regular; in fact they are completely regular, though this is not trivial to prove). Notice also that the product topology on $Y^X$ is precisely induced by the evaluation maps, so $U \subseteq Y^X$ in fact carries the subspace topology and is thus a topology of pointwise convergence. We give some examples of this:
	%
	\begin{enumerate}
		\item Let $X$ be a topological vector space with topological dual $X^*$. Then the \emph{weak$^*$-topology} on $X^*$ is the initial topology induced by the collection of evaluation maps $\ev_x \colon X^* \to \bbK$. Since $\bbK$ is itself a normed space, the above shows that the weak$^*$-topology is a seminorm topology.

		\item Let $X$ and $Y$ be normed spaces, and consider the space $\calB(X,Y)$ of bounded linear maps $X \to Y$. We equip this space with the \emph{strong operator topology}, defined as the initial topology induced by the evaluation maps $\ev_x \colon \calB(X,Y) \to Y$. More concretely, the topology is induced by seminorms $T \mapsto \norm{Tx}$, so a net $(T_i)$ in $\calB(X,Y)$ converges to $T$ iff $\norm{T_i x - Tx} \to 0$ for all $x \in X$.
		
		Notice that the SOT is coarser than the norm topology, since if $T_i \to T$ in the norm topology, then
		%
		\begin{equation*}
			\norm{T_i x - Tx}
				\leq \norm{T_i - T} \, \norm{x}
				\to 0,
		\end{equation*}
		%
		so $T_i \to T$ in the SOT.
		
		\item In the same setup, the \emph{weak operator topology} on $\calB(X,Y)$ is the initial topology induced by maps $\Phi_{x,\phi} = \phi \circ \ev_x \colon \calB(X,Y) \to \bbK$ given by $\Phi_{x,\phi}(T) = \phi(Tx)$ for $x \in X$ and $\phi \in Y^*$, where $Y^*$ is the topological dual of $Y$. That is, contrary to the strong operator topology we do not require the evaluation maps $\ev_x$ themselves to be continuous, only the compositions $\phi \circ \ev_x$. Hence the WOT is coarser than the SOT, since if $\ev_x$ is continuous then so is $\phi \circ \ev_x$.
		
		We claim that the WOT is also Hausdorff. This is not immediate from the above since the generating functions are not evaluation maps. But notice that $Y^*$ separates points in $Y$ by Theorem~5.8c. For distinct $T,S \in \calL(X,Y)$ there is a $x \in X$ with $Tx \neq Sx$, and then a $\phi \in Y^*$ with $\phi(Tx) \neq \phi(Sx)$. Hence the functions $\Phi_{x,\phi}$ separate points in $\calB(X,Y)$.
		
		If $\calH$ is a Hilbert space, then the weak operator topology on $\calB(X,\calH)$ is also induced by maps $T \mapsto \inner{Tx}{y}$ by the Riesz--FrÃ©chet theorem (Theorem~5.25). In this case a net $(T_i)$ converges to $T$ iff $\inner{T_i x}{y} \to \inner{Tx}{y}$ for all $x \in X$ and $y \in \calH$.
	\end{enumerate}
\end{remarkbreak}


\section{Hilbert Spaces}

\begin{remark}
	We give a different proof of the Cauchy--Schwarz inequality using (very) basic properties of orthogonal projections:
	%
	\begin{displaytheorem}
		If $X$ is a inner product space over $\bbK$, then
		%
		\begin{equation}
			\label{eq:Cauchy-Schwarz}
			\abs{ \inner{x}{y} }
				\leq \norm{x} \, \norm{y}
		\end{equation}
		%
		for all $x,y \in X$, with equality if and only if $x$ and $y$ are linearly dependent.
	\end{displaytheorem}
	%
	This is obvious if $y = 0$, so assume not. The \emph{projection} of $x$ on $y$ is the unique vector $p \in \Span(y)$ such that $y \perp x - p$. This exists and is unique, for notice that for $\alpha \in \bbK$ we have
	%
	\begin{equation*}
		0
			= \inner{x - \alpha y}{y}
			= \inner{x}{y} - \alpha \inner{y}{y}
	\end{equation*}
	%
	if and only if
	%
	\begin{equation*}
		\alpha
			= \frac{ \inner{x}{y} }{ \inner{y}{y} },
	\end{equation*}
	%
	so $p = \alpha y$. Notice that $p$ has the property that $x = p$ if and only if $x$ and $y$ are linearly dependent. The \enquote{only if} part is obvious, and the converse follows since if $x = \beta y$ for some $\beta \in \bbK$ then, plugging in above, we find that $\alpha = \beta$.

	Also notice that $p \perp x - p$. Writing $x = p + (x - p)$, Pythagoras' theorem thus implies that
	%
	\begin{equation}
		\label{eq:Cauchy-Schwarz-Pythagoras}
		\norm{x}^2
			= \norm{p}^2 + \norm{x - p}^2
			\geq \norm{p}^2,
	\end{equation}
	%
	with equality just when $x = p$, i.e. when $x$ and $y$ are linearly dependent. Inserting the formula above for $p$, the inequality \cref{eq:Cauchy-Schwarz-Pythagoras} is equivalent to
	%
	\begin{equation*}
		\norm{x}
			\geq \norm{p}
			= \frac{ \abs{\inner{x}{y}} }{ \norm{y} }
			= \frac{ \abs{\inner{x}{y}} }{ \norm{y}^2 } \norm{y}
	\end{equation*}
	%
	which in turn is equivalent to \cref{eq:Cauchy-Schwarz}.
\end{remark}

\chapter{$L^p$-spaces}

\section{Basic Theory of $L^p$-spaces}

\begin{remarkbreak}[The space $L^\infty(\mu)$]
	Let $(X,\calE,\mu)$ be a measure space, and let $f \in \measurable(\calE)$. We prefer to define the essential supremum of $f$ with respect to $\mu$ as
	%
	\begin{equation*}
		\norm{f}_\infty
			= \inf \set{ R > 0 }{ \text{$\abs{f} \leq R$ $\mu$-a.e.} },
	\end{equation*}
	%
	which is clearly equivalent to Folland's definition. If $R > \norm{f}_\infty$ then $\mu(\{\abs{f} > R\}) = 0$, so the set
	%
	\begin{equation*}
		E
			\defn \{ \abs{f} > \norm{f}_\infty \}
			= \bigunion_{n\in\naturals} \biggl\{ \abs{f} > \norm{f}_\infty + \frac{1}{n} \biggr\}
	\end{equation*}
	%
	is also a null set.
	
	The function $\tilde f = f \indicator{K^c}$ then equals $f$ a.e., and we clearly have $\norm{\tilde f}_\infty = \norm{f}_\infty$. Furthermore, since $\abs{\tilde f} \leq \norm{f}_\infty$ everywhere, we also have $\norm{\tilde f}_{\sup} \leq \norm{\tilde f}_\infty$. The opposite inequality follows since $\{ \abs{\tilde f} > R \}$ has positive measure for all $R < \norm{\tilde f}_\infty$. Hence $\norm{\tilde f}_{\sup} = \norm{\tilde f}_\infty$, so if we only consider functions up to null sets we may replace any $f \in \measurable(\calE)$ by a function $\tilde f \in \measurable(\calE)$ whose supremum agrees with its essential supremum. Furthermore, if $\norm{f}_\infty < \infty$, i.e. if $f \in L^\infty(\mu)$, then $\tilde f$ is bounded.
	
	This yields another interpretation of $L^\infty(\mu)$-functions, namely as those functions that arise from bounded measurable functions by altering them on a (measurable) $\mu$-null set.

	It might seem possible to alter a function $f$ on a null set and allow it to \emph{attain} its essential supremum. This is only possible if the measure space $(X,\calE,\mu)$ has nonempty null sets. However, consider for instance the space $(\naturals, \powerset{\naturals}, \tau)$, where $\tau$ is the counting measure. On this space the function $f(n) = 1-1/n$ has (essential) supremum $1$, but it does not attain it. It also cannot be altered on a nonempty null set, since there are no such sets.
\end{remarkbreak}

\addtocounter{section}{1}
\section{Some Useful Inequalities}

\begin{remarkbreak}[Minkowski's inequality for integrals]
	We give a different proof of Theorem~6.19 that does not require duality. Assume that $f \geq 0$ and let $p \in (1,\infty)$ and $H(x) = \int_Y f(x,y) \dif\nu(y)$. Notice that the left-hand side of the inequality is $\norm{H}_p$. Then Tonelli's theorem and HÃ¶lder's inequality imply that
	%
	\begin{align*}
		\norm{H}_p^p
			&= \int_X \int_Y f(x,y) \dif\nu(y) H(x)^{p-1} \dif\mu(x) \\
			&= \int_Y \int_X f(x,y) H(x)^{p-1} \dif\mu(x) \dif\nu(y) \\
			&\leq \int_Y \Bigl( \int_X f(x,y)^p \dif\mu(x) \Bigr)^{1/p} \Bigl( \int_X H(x)^{q(p-1)} \dif\mu(x) \Bigr)^{1/q} \dif\nu(y) \\
			&= \int_Y \Bigl( \int_X f(x,y)^p \dif\mu(x) \Bigr)^{1/p} \norm{H}_p^{p-1} \dif\nu(y).
	\end{align*}
	%
	If $\norm{H}_p < \infty$ then the claim follows, so assume that $\norm{H}_p = \infty$. Choose sequences $(A_n)_{n \in \naturals}$ and $(B_m)_{m \in \naturals}$ of measurable subsets of $X$ and $Y$, respectively, such that $A_n \uparrow X$ and $B_m \uparrow X$, and such that $\mu(A_n) < \infty$ and $\nu(B_m) < \infty$. For $k \in \naturals$ let $f_k = f \meet k$ and notice that replacing $f$ in the definition of $H$ with $\indicator{A_n} \indicator{B_m} f_k$ yields $\norm{H}_p < \infty$, so we may apply Minkowski's inequality to this function:
	%
	\begin{equation*}
		\biggl( \int_{A_n} \Bigl( \int_{B_m} f_k(x,y) \dif\nu(y) \Bigr)^p \dif\mu(x) \biggr)^{1/p}
			\leq \int_{B_m} \Bigl( \int_{A_n} f_k(x,y)^p \dif\mu(x) \Bigr)^{1/p} \dif\nu(y).
	\end{equation*}
	%
	Letting $n,m,k \to \infty$, monotone convergence yields the theorem.

	The second part for $p \in [1,\infty)$ follows by applying the first part to $\abs{f}$ and using the triangle inequality for integrals.
\end{remarkbreak}



\addtocounter{chapter}{1}
\chapter{Elements of Fourier Analysis}

\section{Preliminaries}

\newcommand{\calS}{\mathcal{S}}
\newcommand{\schwartz}{\calS}

\begin{remarkbreak}[Completeness of the Schwartz space]
	We elaborate on the proof of Proposition~8.2. Let $(f_n)_{n\in\naturals}$ be a Cauchy sequence in $\schwartz$. Then the sequence $(\partial^\alpha \!f_n)_{n\in\naturals}$ is a Cauchy sequence in the uniform norm for all multi-indices $\alpha$, since $\norm{\partial^\alpha \!f_n}_{\sup} = \norm{f_n}_{(0,\alpha)}$. Hence $\partial^\alpha \!f_n$ converges uniformly to a function $g_\alpha$ by completeness in the uniform norm. We then have
	%
	\begin{equation*}
		f_n(x + te_i) - f_n(x)
			= \int_0^t \partial_i f_n(x + se_i) \dif s.
	\end{equation*}
	%
	Letting $n \to \infty$, $\partial_i f_n$ converges to $g_{e_i}$ uniformly, so it follows that
	%
	\begin{equation*}
		g_0(x + te_i) - g_0(x)
			= \int_0^t g_{e_i}(x + se_i) \dif s.
	\end{equation*}
	%
	The fundamental theorem of calculus then implies that $\partial_j g_0$ exists and equals $g_{e_i}$, so it follows by induction that $g_\alpha = \partial^\alpha \!g_0$. It remains to be shown that $\norm{f_n - g_0}_{(N,\alpha)} \to 0$ for all $N$ and $\alpha$.

	To this end, let $\epsilon > 0$ and choose $M \in \naturals$ such that $m,n \geq M$ implies that $\norm{f_n - f_m}_{(N,\alpha)} < \epsilon$. For every $x \in \reals^d$ we thus have
	%
	\begin{equation*}
		(1 + \norm{x})^N \abs{\partial^\alpha \!f_n(x) - \partial^\alpha \!f_m(x)}
			< \epsilon.
	\end{equation*}
	%
	Letting $m \to \infty$ we get
	%
	\begin{equation*}
		(1 + \norm{x})^N \abs{\partial^\alpha \!f_n(x) - \partial^\alpha \!g_0(x)}
			\leq \epsilon.
	\end{equation*}
	%
	Taking the supremum we find that $n \geq M$ implies that $\norm{f_n - g_0}_{(N,\alpha)} \leq \epsilon$, showing that $f_n \to g_0$ in $\schwartz$.
\end{remarkbreak}


\section{Convolutions}

\begin{remarkbreak}[Associativity of convolution]
	If $f,g,h \in \calM(\borel(\reals^d))$, then we define the function $k \colon \reals^{3d} \to \complex$ by
	%
	\begin{equation*}
		k(x,y,z)
			= f(y) g(x-y-z) h(z).
	\end{equation*}
	%
	This is clearly measurable, so we may consider the function $K \colon \reals^d \to [0,\infty]$ given by
	%
	\begin{equation*}
		K(x)
			= \int_{\reals^{2d}} \abs{k(x,\,\cdot\,,\,\cdot\,)} \dif \lambda_{2d}.
	\end{equation*}
	%
	By Tonelli's theorem $K$ is also measurable, so the set
	%
	\begin{equation*}
		\Delta(f,g,h)
			= \set{x \in \reals^d }{ k(x,\,\cdot\,,\,\cdot\,) \in \calL^1(\lambda_{2d}) }
			= \set{x \in \reals^d }{ K(x) < \infty }
	\end{equation*}
	%
	is measurable. For $x \in \Delta(f,g,h)$, Fubini's theorem thus implies that
	%
	% For $x \in \reals^d$ we have
	% %
	% \begin{align*}
	% 	\int_{\reals^d} \abs{f * g(x-z) h(z)} \dif\lambda_d(z)
	% 		&= \int_{\reals^d} \abs{g * f(x-z) h(z)} \dif\lambda_d(z) \\
	% 		&\leq \int_{\reals^d} \biggl( \int_{\reals^d} \abs{f(y) g(x-y-z)} \dif\lambda_d(y) \biggr) \abs{h(z)} \dif\lambda_d(z) \\
	% 		&= \int_{\reals^d} \biggl( \int_{\reals^d} \abs{f(y) g(x-y-z) h(z)} \dif\lambda_d(y) \biggr) \dif\lambda_d(z) \\
	% 		&= \int_{\reals^{2d}} \abs{k(x,\,\cdot\,,\,\cdot\,)} \dif\lambda_{2d} \\
	% 		&= K(x).
	% \end{align*}
	% %
	% Hence if $x \in \Delta(f,g,h)$, then ????
	%
	\begin{align*}
		(f * g) * h(x)
			&= (g * f) * h(x) \\
			&= \int_{\reals^d} g * f(x-z) h(z) \dif z \\
			&= \int_{\reals^d} \biggl( \int_{\reals^d} f(y) g(x-z-y) \dif y \biggr) h(z) \dif z \\
			&= \int_{\reals^d} \biggl( \int_{\reals^d} f(y) g(x-z-y) h(z) \dif y \biggr) \dif z \\
			&= \int_{\reals^d} \biggl( \int_{\reals^d} f(y) g(x-y-z) h(z) \dif z \biggr) \dif y \\
			&= \int_{\reals^d} f(y) \biggl( \int_{\reals^d} g(x-y-z) h(z) \dif z \biggr) \dif y \\
			&= \int_{\reals^d} f(y) h * g(x-y) \dif y \\
			&= f * (h * g)(x) \\
			&= f * (g * h)(x).
	\end{align*}
	%
	Thus convolution is associative on $\Delta(f,g,h)$. If $f,g,h \in \calL^1(\lambda_d)$, then it is easy to show that $\Delta(f,g,h)^c$ is a Lebesgue null-set. However, it is not clear whether (and I don't see why it should be true that) $\Delta(f,g,h)$ is the same as $\Delta(f*g,h)$ or $\Delta(f,g*h)$.
\end{remarkbreak}


\section{The Fourier Transform}

\begin{remarkbreak}[Uniform continuity of Fourier transforms]
	Let $f \in L^1(\reals^d)$. For $\xi, \eta \in \reals^d$ we then have
	%
	\begin{align*}
		\abs{ \hat f(\xi) - \hat f(\eta) }
			&\leq \int_{\reals^d} \abs{f(x)} \, \abs[\big]{ \e^{-2\pi \iu \inner{\xi}{x}} - \e^{-2\pi \iu \inner{\eta}{x}} } \dif x \\
			&= \int_{\reals^d} \abs{f(x)} \, \abs[\big]{ \e^{-2\pi \iu \inner{\xi-\eta}{x}} - 1} \dif x.
	\end{align*}
	%
	Since $2\abs{f}$ is integrable and dominates the integrand, the dominated convergence theorem implies that the above goes to zero as $\xi-\eta \to 0$.
\end{remarkbreak}

\end{document}